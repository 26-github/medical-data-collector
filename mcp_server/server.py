from fastmcp import FastMCP
import sys
import logging
from datetime import datetime
import requests
import json
import os
import time
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ  get_db_qa ç›¸å…³çš„å¯¼å…¥
from typing_extensions import List, TypedDict
from langchain_core.documents import Document
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langgraph.constants import START
from langgraph.graph import StateGraph
# å·²æ”¹ç”¨é˜¿é‡Œäº‘DashScopeæ¨¡å‹ï¼Œç§»é™¤init_chat_modelå¯¼å…¥

# ç¦ç”¨Hugging Faceç¬¦å·é“¾æ¥è­¦å‘Š
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

# è®¾ç½®è¯¦ç»†çš„æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("FastMCP-Server")

# ç›´è¿é˜¿é‡Œäº‘ DashScope Embeddingsï¼ˆOpenAIå…¼å®¹ç«¯ç‚¹åœ¨éƒ¨åˆ†ç‰ˆæœ¬ä¸‹ä¸é€šç”¨å®¢æˆ·ç«¯å­—æ®µä¸ä¸€è‡´ï¼Œè¿™é‡Œæ‰‹å†™è½»é‡å®ç°ï¼‰
class DashScopeEmbeddings:
    def __init__(
        self,
        api_key: str,
        model: str = "text-embedding-v4",
        api_base: str = "https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings",
        request_timeout_seconds: int = 30,
        sleep_between_requests_seconds: float = 0.0,
    ) -> None:
        self.api_key = api_key
        self.model = model
        self.api_base = api_base.rstrip("/")
        self.timeout = request_timeout_seconds
        self.sleep_seconds = sleep_between_requests_seconds

    def embed_query(self, text: str):
        # ç¡®ä¿ä¸ºå­—ç¬¦ä¸²
        if not isinstance(text, str):
            try:
                text = json.dumps(text, ensure_ascii=False)
            except Exception:
                text = str(text)
        payload = {"model": self.model, "input": text}
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        resp = requests.post(self.api_base, headers=headers, json=payload, timeout=self.timeout)
        resp.raise_for_status()
        data = resp.json()
        if "data" in data and data["data"] and "embedding" in data["data"][0]:
            return data["data"][0]["embedding"]
        raise ValueError(f"æ— æ•ˆçš„Embeddingå“åº”: {data}")

    def embed_documents(self, texts):
        embeddings = []
        for t in texts:
            try:
                vec = self.embed_query(t)
            except Exception:
                # å…œåº•ï¼Œé¿å…å•æ¡å¤±è´¥ä¸­æ–­æ‰¹é‡
                vec = [0.0] * 1024
            embeddings.append(vec)
            if self.sleep_seconds:
                time.sleep(self.sleep_seconds)
        return embeddings

# åˆ›å»ºMCPæœåŠ¡å™¨
mcp = FastMCP(
    name="medical_assistant_tools",
    instructions="""
    ä¸“ä¸šåŒ»ç–—åŠ©æ‰‹å·¥å…·æœåŠ¡å™¨ - æä¾›å…¨é¢çš„åŒ»ç–—ä¿¡æ¯æŸ¥è¯¢å’Œè¾…åŠ©åŠŸèƒ½

    ğŸ¥ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼š
    
    1. ã€åŒ»å­¦çŸ¥è¯†é—®ç­”ã€‘- medical_qa_search
       - åŸºäºä¸“ä¸šåŒ»å­¦çŸ¥è¯†åº“çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
       - æ”¯æŒç–¾ç—…ç—‡çŠ¶ã€è¯Šæ–­ã€æ²»ç–—æ–¹æ³•ç­‰å…¨æ–¹ä½æŸ¥è¯¢
       - ä½¿ç”¨å…ˆè¿›çš„æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œæä¾›å‡†ç¡®å¯é çš„åŒ»å­¦ä¿¡æ¯
       - é€‚ç”¨åœºæ™¯ï¼šç–¾ç—…ç§‘æ™®ã€æ²»ç–—æŒ‡å—ã€åŒ»å­¦æœ¯è¯­è§£é‡Šç­‰
    
    2. ã€åŒ»é™¢ä¿¡æ¯æŸ¥è¯¢ã€‘- get_hospital_info
       - å…¨å›½åŒ»é™¢æ•°æ®åº“æŸ¥è¯¢æœåŠ¡
       - æ”¯æŒå¤šç»´åº¦æœç´¢ï¼šåŒ»é™¢åç§°ã€åœ°å€ã€ç­‰çº§ã€ç±»å‹ç­‰
       - æä¾›è¯¦ç»†åŒ»é™¢ä¿¡æ¯ï¼šè”ç³»æ–¹å¼ã€è§„æ¨¡ã€æ€§è´¨ã€ç®€ä»‹ç­‰
       - é€‚ç”¨åœºæ™¯ï¼šå°±åŒ»æ¨èã€åŒ»é™¢å¯¹æ¯”ã€åŒ»ç–—èµ„æºæŸ¥è¯¢ç­‰
    
    3. ã€æ—¶é—´è¾…åŠ©å·¥å…·ã€‘
       - get_current_date: è·å–å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYYå¹´MMæœˆDDæ—¥
       - get_current_time: è·å–å½“å‰æ—¶é—´ï¼Œæ ¼å¼ä¸ºHH:MM:SS
       - é€‚ç”¨åœºæ™¯ï¼šåŒ»ç–—è®°å½•æ—¶é—´æˆ³ã€é¢„çº¦æ—¶é—´å‚è€ƒç­‰

    ğŸ¯ ä½¿ç”¨æŒ‡å—ï¼š
    - åŒ»å­¦é—®ç­”ï¼šç›´æ¥è¾“å…¥åŒ»å­¦ç›¸å…³é—®é¢˜ï¼Œå¦‚"ç³–å°¿ç—…çš„ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ"
    - åŒ»é™¢æŸ¥è¯¢ï¼šå¯æŒ‰åŒ»é™¢åç§°ã€åœ°åŒºã€ç­‰çº§ç­‰æ¡ä»¶æœç´¢
    - æ—¶é—´æŸ¥è¯¢ï¼šæ— éœ€å‚æ•°ï¼Œç›´æ¥è·å–å½“å‰æ—¥æœŸæ—¶é—´
    
    âš ï¸ é‡è¦è¯´æ˜ï¼š
    - æ‰€æœ‰åŒ»å­¦ä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®
    - å»ºè®®åœ¨ä¸“ä¸šåŒ»ç”ŸæŒ‡å¯¼ä¸‹è¿›è¡Œè¯Šæ–­å’Œæ²»ç–—
    - åŒ»é™¢ä¿¡æ¯æ¥æºäºå…¬å¼€æ•°æ®åº“ï¼Œå¦‚æœ‰å˜åŠ¨è¯·ä»¥å®˜æ–¹ä¸ºå‡†
    """,
)

# åˆå§‹åŒ–QAæ£€ç´¢ç³»ç»Ÿ
try:
    dashscope_api_key = os.getenv("DASHSCOPE_API_KEY", "sk-c258c59319a44549bbea71470bc00e62")
    if not dashscope_api_key:
        logger.warning("DASHSCOPE_API_KEY not found, QA retrieval system will not be available")
        qa_system_available = False
    else:
        # åˆå§‹åŒ–é˜¿é‡Œäº‘DashScopeæ¨¡å‹ï¼ˆå¯¹è¯ï¼‰- æ·»åŠ è¶…æ—¶å’Œé‡è¯•é…ç½®
        llm = ChatOpenAI(
            model="qwen-max",
            temperature=0.1,
            request_timeout=60,  # è®¾ç½®60ç§’è¶…æ—¶
            max_retries=3,       # æœ€å¤§é‡è¯•3æ¬¡
            openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
            openai_api_key=os.getenv("DASHSCOPE_API_KEY"),
        )
        
        # ä½¿ç”¨é˜¿é‡Œäº‘çš„text-embedding-v4æ¨¡å‹ï¼ˆç›´è¿DashScope Embeddingsç«¯ç‚¹ï¼Œé¿å…å…¼å®¹å±‚å­—æ®µå·®å¼‚å¯¼è‡´400ï¼‰
        embeddings = DashScopeEmbeddings(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            model="text-embedding-v4",
            api_base="https://dashscope.aliyuncs.com/compatible-mode/v1/embeddings",
            request_timeout_seconds=30,
            sleep_between_requests_seconds=0.0,
        )
        logger.info("âœ… æˆåŠŸä½¿ç”¨é˜¿é‡Œäº‘çš„text-embedding-v4æ¨¡å‹")
        
        vector_store = Chroma(
            collection_name="aliyun_text_embedding_v4_collection",
            embedding_function=embeddings,
            persist_directory="./chroma_langchain_db"
        )
        
        # é˜¿é‡Œäº‘DashScopeä¸æ”¯æŒrerankerï¼Œä½¿ç”¨ç®€å•çš„ç›¸ä¼¼åº¦æ’åº
        reranker = None
        
        # ä¸ºHyDEï¼ˆå‡è®¾æ€§æ–‡æ¡£åµŒå…¥ï¼‰åˆ›å»ºä¸€ä¸ªæç¤º
        hyde_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»å­¦ä¸“å®¶ã€‚åŸºäºç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªè¯¦ç»†ã€å‡†ç¡®çš„å‡è®¾æ€§ç­”æ¡ˆæ–‡æ¡£ï¼Œè¿™ä¸ªç­”æ¡ˆåº”è¯¥ï¼š

            1. ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
            2. åŒ…å«ç›¸å…³çš„åŒ»å­¦æœ¯è¯­å’Œä¸“ä¸šè¡¨è¿°
            3. ç»“æ„åŒ–åœ°ç»„ç»‡ä¿¡æ¯ï¼ˆå¦‚ç—‡çŠ¶ã€è¯Šæ–­ã€æ²»ç–—ç­‰ï¼‰
            4. è¯­è¨€é£æ ¼ç±»ä¼¼äºåŒ»å­¦æŒ‡å—ã€æ•™ç§‘ä¹¦æˆ–ä¸“ä¸šæ–‡çŒ®
            5. å†…å®¹è¯¦å®ï¼Œæ¶µç›–é—®é¢˜çš„å„ä¸ªæ–¹é¢

            è¯·æ³¨æ„ï¼šè¿™ä¸ªç­”æ¡ˆå°†ç”¨äºæ£€ç´¢ç›¸ä¼¼çš„åŒ»å­¦æ–‡æ¡£ï¼Œå› æ­¤è¯·å°½å¯èƒ½ä½¿ç”¨æ ‡å‡†çš„åŒ»å­¦è¡¨è¿°å’Œæœ¯è¯­ã€‚

            ç”¨æˆ·é—®é¢˜ï¼š{question}

            å‡è®¾æ€§ç­”æ¡ˆï¼š""",
            input_variables=["question"],
        )

        answer_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ç§‘æ™®åŠ©æ‰‹ï¼Œé€šè¿‡ä»æ–‡æ¡£ä¸­æå–ä¿¡æ¯æ¥ä¸ºç”¨æˆ·å…¨é¢ç§‘æ™®çŸ¥è¯†ï¼Œæ–¹æ–¹é¢é¢éƒ½è¦è®²åˆ°ã€‚åªèƒ½ä½¿ç”¨æä¾›çš„æ–‡æ¡£å†…å®¹æ¥å›ç­”é—®é¢˜ï¼Œä¸èƒ½ä½¿ç”¨å…¶ä»–ä¿¡æ¯ã€‚

        ä¸Šä¸‹æ–‡ï¼š
        {context}

        é—®é¢˜ï¼š{question}

        ç­”æ¡ˆï¼š""",
            input_variables=["context", "question"]
        )

        class State(TypedDict):  # å®šä¹‰çŠ¶æ€ç±»å‹
            question: str
            context: List[Document]
            reranked_context: List[Document]  # æ·»åŠ é‡æ’åºåçš„æ–‡æ¡£å­—æ®µ
            answer: str

        def retrieve(state: State):  # QAå¢å¼ºçš„æ–‡æ¡£æ£€ç´¢
            question = state["question"]
            # å¼ºåˆ¶å­—ç¬¦ä¸²åŒ–ï¼Œé¿å… embeddings ç«¯å£æ”¶åˆ°éå­—ç¬¦ä¸²
            if not isinstance(question, str):
                try:
                    import json as _json
                    question = _json.dumps(question, ensure_ascii=False)
                except Exception:
                    question = str(question)
            logger.info(f"ğŸ” å¼€å§‹QAå¢å¼ºæ£€ç´¢ï¼Œé—®é¢˜ï¼š{question}")

            # é˜¶æ®µ1ï¼šç›´æ¥æ£€ç´¢QAæ–‡æ¡£ï¼ˆä½¿ç”¨é—®é¢˜æœ¬èº«ï¼‰
            logger.info("ğŸ“‹ é˜¶æ®µ1ï¼šæ£€ç´¢QAé—®ç­”å¯¹...")
            try:
                all_qa_docs = vector_store.similarity_search(question, k=20)
            except Exception as e:
                logger.error(f"é˜¶æ®µ1 similarity_search å‡ºé”™: {e}")
                raise
            qa_docs = [doc for doc in all_qa_docs if doc.metadata.get('content_type') in ['generated_qa', 'target_qa']][:8]
            logger.info(f"æ‰¾åˆ° {len(qa_docs)} ä¸ªQAæ–‡æ¡£")

            # é˜¶æ®µ2ï¼šç›´æ¥æ£€ç´¢åŸå§‹æ–‡æ¡£ï¼ˆè·³è¿‡HyDEä»¥æå‡é€Ÿåº¦ï¼‰
            logger.info("ğŸ“„ é˜¶æ®µ2ï¼šç›´æ¥æ£€ç´¢åŸå§‹æ–‡æ¡£ï¼ˆè·³è¿‡HyDEç”Ÿæˆï¼‰...")
            
            # ç›´æ¥ä½¿ç”¨åŸå§‹é—®é¢˜æ£€ç´¢åŸå§‹æ–‡æ¡£ï¼Œè·³è¿‡HyDEå‡è®¾æ€§ç­”æ¡ˆç”Ÿæˆ
            try:
                all_original_docs = vector_store.similarity_search(question, k=20)
            except Exception as e:
                logger.error(f"åŸå§‹æ–‡æ¡£æ£€ç´¢å‡ºé”™: {e}")
                raise
            original_docs = [doc for doc in all_original_docs if
                             doc.metadata.get('content_type') not in ['generated_qa', 'target_qa']][:8]
            logger.info(f"âš¡ å¿«é€Ÿæ£€ç´¢åˆ° {len(original_docs)} ä¸ªåŸå§‹æ–‡æ¡£")

            # åˆå¹¶ç»“æœï¼ŒQAæ–‡æ¡£ä¼˜å…ˆ
            all_docs = qa_docs + original_docs

            # å»é‡ï¼ˆåŸºäºå†…å®¹ç›¸ä¼¼æ€§ï¼‰
            unique_docs = []
            seen_content = set()

            for doc in all_docs:
                # ä½¿ç”¨å†…å®¹çš„å‰100ä¸ªå­—ç¬¦ä½œä¸ºå»é‡ä¾æ®
                content_key = doc.page_content[:100]
                if content_key not in seen_content:
                    seen_content.add(content_key)
                    unique_docs.append(doc)

            logger.info(f"ğŸ¯ æ£€ç´¢å®Œæˆï¼Œå…±è·å¾— {len(unique_docs)} ä¸ªå”¯ä¸€æ–‡æ¡£ï¼ˆQA: {len(qa_docs)}, åŸå§‹: {len(original_docs)}ï¼‰")

            # è¿”å›æœ€å¤š15ä¸ªæ–‡æ¡£ç”¨äºé‡æ’åº
            return {"context": unique_docs[:15]}

        def rerank(state: State):  # ç®€å•çš„åŸºäºç›¸ä¼¼åº¦çš„é‡æ’åºï¼ˆé˜¿é‡Œäº‘DashScopeæ¨¡å‹ï¼‰
            query = state["question"]
            docs = state["context"]

            # é˜¿é‡Œäº‘DashScopeæ¨¡å‹ä¸æ”¯æŒrerankerï¼Œä½¿ç”¨ç®€å•çš„ç›¸ä¼¼åº¦æ’åº
            try:
                # ä¼˜å…ˆé€‰æ‹©QAæ–‡æ¡£ï¼Œç„¶åé€‰æ‹©åŸå§‹æ–‡æ¡£
                qa_docs = [doc for doc in docs if doc.metadata.get('content_type') in ['generated_qa', 'target_qa']]
                original_docs = [doc for doc in docs if doc.metadata.get('content_type') not in ['generated_qa', 'target_qa']]
                
                # å°†QAæ–‡æ¡£æ’åœ¨å‰é¢ï¼ŒåŸå§‹æ–‡æ¡£æ’åœ¨åé¢
                reranked_docs = qa_docs[:6] + original_docs[:4]  # æœ€å¤š6ä¸ªQAæ–‡æ¡£ + 4ä¸ªåŸå§‹æ–‡æ¡£
                
                # å¦‚æœä¸è¶³10ä¸ªï¼Œè¡¥å……å‰©ä½™æ–‡æ¡£
                remaining_docs = [doc for doc in docs if doc not in reranked_docs]
                while len(reranked_docs) < min(10, len(docs)) and remaining_docs:
                    reranked_docs.append(remaining_docs.pop(0))

                logger.info(f"ç®€å•é‡æ’åºå®Œæˆï¼Œä» {len(docs)} ä¸ªæ–‡æ¡£ä¸­é€‰æ‹©äº† {len(reranked_docs)} ä¸ª")

                # åˆ†æé‡æ’åºåçš„æ–‡æ¡£ç±»å‹
                qa_count = len(
                    [doc for doc in reranked_docs[:10] if doc.metadata.get('content_type') in ['generated_qa', 'target_qa']])
                original_count = len(reranked_docs[:10]) - qa_count
                logger.info(f"ğŸ“Š é‡æ’åºç»“æœï¼šQAæ–‡æ¡£ {qa_count} ä¸ªï¼ŒåŸå§‹æ–‡æ¡£ {original_count} ä¸ª")

                return {"reranked_context": reranked_docs[:10]}  # ç¡®ä¿è¿”å›æœ€å¤š10ä¸ªæ–‡æ¡£

            except Exception as e:
                logger.error(f"é‡æ’åºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                logger.info("ä½¿ç”¨åŸå§‹æ–‡æ¡£é¡ºåºä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
                # å¦‚æœé‡æ’åºå¤±è´¥ï¼Œè¿”å›å‰10ä¸ªåŸå§‹æ–‡æ¡£
                return {"reranked_context": docs[:10]}

        def generate(state: State):  # QAå¢å¼ºçš„ç­”æ¡ˆç”Ÿæˆ
            # ä½¿ç”¨é‡æ’åºåçš„æ–‡æ¡£ï¼Œæ™ºèƒ½ç»„ç»‡QAå’ŒåŸå§‹æ–‡æ¡£å†…å®¹
            max_doc_length = 1200  # æ¯ä¸ªæ–‡æ¡£æœ€å¤§å­—ç¬¦æ•°
            max_total_length = 8000  # æ€»ä¸Šä¸‹æ–‡æœ€å¤§å­—ç¬¦æ•°

            formatted_docs = []
            total_length = 0
            qa_count = 0
            original_count = 0

            for i, doc in enumerate(state["reranked_context"], 1):
                content_type = doc.metadata.get('content_type', 'unknown')

                # æ ¼å¼åŒ–æ–‡æ¡£å†…å®¹ï¼ŒåŒºåˆ†QAå’ŒåŸå§‹æ–‡æ¡£
                if content_type in ['generated_qa', 'target_qa']:
                    qa_count += 1
                    doc_header = f"ã€QAé—®ç­”å¯¹ {qa_count}ã€‘"
                    if content_type == 'target_qa':
                        doc_header += "ï¼ˆä¸“ä¸šçŸ¥è¯†åº“ï¼‰"
                    elif content_type == 'generated_qa':
                        doc_header += f"ï¼ˆæ¥æºï¼š{doc.metadata.get('source_file', 'æœªçŸ¥')}ï¼‰"
                else:
                    original_count += 1
                    file_type = doc.metadata.get('file_type', 'unknown')
                    source_file = doc.metadata.get('source_file', 'æœªçŸ¥')
                    doc_header = f"ã€åŸå§‹æ–‡æ¡£ {original_count}ã€‘ï¼ˆ{file_type.upper()}ï¼š{source_file}ï¼‰"

                # æˆªæ–­æ–‡æ¡£å†…å®¹
                doc_content = doc.page_content[:max_doc_length]
                formatted_content = f"{doc_header}\n{doc_content}"

                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ€»é•¿åº¦é™åˆ¶
                content_with_separator = formatted_content + "\n\n"
                if total_length + len(content_with_separator) <= max_total_length:
                    formatted_docs.append(formatted_content)
                    total_length += len(content_with_separator)
                else:
                    # å¦‚æœä¼šè¶…è¿‡é™åˆ¶ï¼Œæ·»åŠ æˆªæ–­çš„å†…å®¹
                    remaining_space = max_total_length - total_length - len(doc_header) - 4  # 4 for "\n...\n\n"
                    if remaining_space > 100:
                        truncated_content = doc_content[:remaining_space] + "..."
                        formatted_content = f"{doc_header}\n{truncated_content}"
                        formatted_docs.append(formatted_content)
                    break

            docs_content = "\n\n".join(formatted_docs)
            logger.info(f"ğŸ’¡ ç”Ÿæˆç­”æ¡ˆï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡ï¼š{len(docs_content)} å­—ç¬¦ï¼ˆQAæ–‡æ¡£: {qa_count}, åŸå§‹æ–‡æ¡£: {original_count}ï¼‰")

            # ä½¿ç”¨é“¾å¼è°ƒç”¨ï¼Œé¿å…å°† PromptValue ç›´æ¥ä¼ å…¥æ¨¡å‹å¯¼è‡´çš„ contents ç±»å‹é”™è¯¯
            # æ˜¾å¼æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²å†è°ƒç”¨æ¨¡å‹ï¼Œé¿å…å°† PromptValue ç›´æ¥ä¼ ç»™æ¨¡å‹
            formatted_answer_prompt = answer_prompt.format(
                question=state["question"],
                context=docs_content,
            )
            if not isinstance(formatted_answer_prompt, str):
                formatted_answer_prompt = str(formatted_answer_prompt)
            try:
                response = llm.invoke(formatted_answer_prompt)
            except Exception as e:
                logger.error(f"ç­”æ¡ˆç”Ÿæˆæ¨¡å‹è°ƒç”¨å‡ºé”™: {e}")
                raise
            return {"answer": response}

        # æ„å»ºçŠ¶æ€å›¾
        graph_builder = StateGraph(State)
        graph_builder.add_node("retrieve", retrieve)
        graph_builder.add_node("rerank", rerank)
        graph_builder.add_node("generate", generate)
        graph_builder.add_edge(START, "retrieve")
        graph_builder.add_edge("retrieve", "rerank")
        graph_builder.add_edge("rerank", "generate")
        qa_graph = graph_builder.compile()
        
        qa_system_available = True
        logger.info("QAæ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        
except Exception as e:
    logger.error(f"QAæ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    qa_system_available = False

# MCPå·¥å…·
@mcp.tool()
def get_current_date() -> str:
    """è·å–å½“å‰ç³»ç»Ÿæ—¥æœŸ
    
    è¿™ä¸ªå·¥å…·ç”¨äºè·å–å½“å‰çš„ç³»ç»Ÿæ—¥æœŸï¼Œè¿”å›ä¸­æ–‡æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²ã€‚
    
    ğŸ“… åŠŸèƒ½è¯´æ˜ï¼š
    - è·å–å®æ—¶çš„å½“å‰æ—¥æœŸ
    - è¿”å›æ ¼å¼ï¼šYYYYå¹´MMæœˆDDæ—¥ï¼ˆå¦‚ï¼š2024å¹´12æœˆ19æ—¥ï¼‰
    - åŸºäºç³»ç»Ÿæœ¬åœ°æ—¶é—´
    
    ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š
    - åŒ»ç–—è®°å½•éœ€è¦å½“å‰æ—¥æœŸ
    - é¢„çº¦æŒ‚å·æ—¶é—´å‚è€ƒ
    - ç—…å†è®°å½•æ—¶é—´æˆ³
    - ç”¨è¯å¼€å§‹æ—¥æœŸæ ‡è®°
    
    Returns:
        str: å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸º"YYYYå¹´MMæœˆDDæ—¥"
    
    Example:
        è°ƒç”¨è¯¥å·¥å…·å°†è¿”å›ç±»ä¼¼"2024å¹´12æœˆ19æ—¥"çš„æ—¥æœŸå­—ç¬¦ä¸²
    """
    result = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    logger.info(f"get_current_date called, returning: {result}")
    return result


@mcp.tool()
def get_current_time() -> str:
    """è·å–å½“å‰ç³»ç»Ÿæ—¶é—´
    
    è¿™ä¸ªå·¥å…·ç”¨äºè·å–å½“å‰çš„ç³»ç»Ÿæ—¶é—´ï¼Œè¿”å›24å°æ—¶åˆ¶æ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸²ã€‚
    
    â° åŠŸèƒ½è¯´æ˜ï¼š
    - è·å–å®æ—¶çš„å½“å‰æ—¶é—´
    - è¿”å›æ ¼å¼ï¼šHH:MM:SSï¼ˆå¦‚ï¼š14:30:25ï¼‰
    - ä½¿ç”¨24å°æ—¶åˆ¶
    - åŸºäºç³»ç»Ÿæœ¬åœ°æ—¶é—´
    
    ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š
    - åŒ»ç–—æ“ä½œæ—¶é—´è®°å½•
    - ç”¨è¯æ—¶é—´æé†’
    - æ£€æŸ¥æ—¶é—´æ ‡è®°
    - æ€¥è¯Šæ—¶é—´è®°å½•
    - æ‰‹æœ¯æ—¶é—´è®°å½•
    
    Returns:
        str: å½“å‰æ—¶é—´ï¼Œæ ¼å¼ä¸º"HH:MM:SS"
    
    Example:
        è°ƒç”¨è¯¥å·¥å…·å°†è¿”å›ç±»ä¼¼"14:30:25"çš„æ—¶é—´å­—ç¬¦ä¸²
    """
    result = datetime.now().strftime("%H:%M:%S")
    logger.info(f"get_current_time called, returning: {result}")
    return result


@mcp.tool()
def medical_qa_search(question: str, image_analysis: str = "") -> str:
    """ä¸“ä¸šåŒ»å­¦çŸ¥è¯†åº“æ£€ç´¢é—®ç­”å·¥å…·ï¼ˆæ”¯æŒå›¾åƒåˆ†æå¢å¼ºRAGï¼‰
    
    è¿™æ˜¯ä¸€ä¸ªåŸºäºå…ˆè¿›AIæŠ€æœ¯çš„åŒ»å­¦çŸ¥è¯†æ£€ç´¢ç³»ç»Ÿï¼Œèƒ½å¤Ÿä»ä¸“ä¸šåŒ»å­¦çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶ç”Ÿæˆå‡†ç¡®çš„åŒ»å­¦ç­”æ¡ˆã€‚
    ç°åœ¨æ”¯æŒåŸºäºåŒ»ç–—å›¾åƒåˆ†æç»“æœçš„å¢å¼ºæ£€ç´¢åŠŸèƒ½ã€‚
    
    ğŸ”¬ æŠ€æœ¯ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨HyDEï¼ˆå‡è®¾æ€§æ–‡æ¡£åµŒå…¥ï¼‰æŠ€æœ¯æé«˜æ£€ç´¢ç²¾åº¦
    - ç»“åˆQAé—®ç­”å¯¹å’ŒåŸå§‹åŒ»å­¦æ–‡æ¡£è¿›è¡Œæ£€ç´¢
    - ä½¿ç”¨RankGPTé‡æ’åºç®—æ³•ä¼˜åŒ–ç»“æœç›¸å…³æ€§
    - åŸºäºé˜¿é‡Œäº‘Qwenæ¨¡å‹ç”Ÿæˆä¸“ä¸šç­”æ¡ˆ
    - ğŸ†• æ”¯æŒåŒ»ç–—å›¾åƒåˆ†æç»“æœå¢å¼ºRAGæ£€ç´¢
    
    ğŸ“š çŸ¥è¯†åº“å†…å®¹ï¼š
    - ç–¾ç—…è¯Šæ–­æŒ‡å—
    - æ²»ç–—æ–¹æ¡ˆå’Œç”¨è¯æŒ‡å¯¼
    - ç—‡çŠ¶åˆ†æå’Œé‰´åˆ«è¯Šæ–­
    - åŒ»å­¦æœ¯è¯­å’Œæ¦‚å¿µè§£é‡Š
    - é¢„é˜²ä¿å¥çŸ¥è¯†
    
    Args:
        question (str): åŒ»å­¦ç›¸å…³é—®é¢˜ï¼Œæ”¯æŒä¸­æ–‡è‡ªç„¶è¯­è¨€æé—®
            
            é—®é¢˜ç±»å‹ç¤ºä¾‹ï¼š
            - ç–¾ç—…ç—‡çŠ¶ï¼š"ç³–å°¿ç—…æœ‰ä»€ä¹ˆç—‡çŠ¶ï¼Ÿ"
            - æ²»ç–—æ–¹æ³•ï¼š"é«˜è¡€å‹çš„æ²»ç–—æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ"
            - è¯Šæ–­æŒ‡å—ï¼š"å¦‚ä½•è¯Šæ–­å† å¿ƒç—…ï¼Ÿ"
            - ç”¨è¯æŒ‡å¯¼ï¼š"é˜¿å¸åŒ¹æ—çš„ç”¨æ³•ç”¨é‡æ˜¯ä»€ä¹ˆï¼Ÿ"
            - é¢„é˜²ä¿å¥ï¼š"å¦‚ä½•é¢„é˜²å¿ƒè„‘è¡€ç®¡ç–¾ç—…ï¼Ÿ"
            - æœ¯è¯­è§£é‡Šï¼š"ä»€ä¹ˆæ˜¯å¿ƒæˆ¿é¢¤åŠ¨ï¼Ÿ"
            - æ£€æŸ¥é¡¹ç›®ï¼š"å¿ƒç”µå›¾èƒ½æ£€æŸ¥å‡ºä»€ä¹ˆé—®é¢˜ï¼Ÿ"
            
        image_analysis (str, optional): åŒ»ç–—å›¾åƒåˆ†æç»“æœï¼Œç”¨äºå¢å¼ºRAGæ£€ç´¢
            - æ¥æºäºXå…‰ã€CTã€MRIã€å¿ƒç”µå›¾ã€è¡€æ£€æŠ¥å‘Šç­‰åŒ»ç–—å½±åƒçš„AIåˆ†æ
            - åŒ…å«æ£€æŸ¥ç±»å‹ã€å¼‚å¸¸å‘ç°ã€å…³é”®æŒ‡æ ‡ç­‰åŒ»å­¦ä¿¡æ¯
            - ç³»ç»Ÿä¼šä»ä¸­æå–åŒ»å­¦å…³é”®è¯æ¥å¢å¼ºæ£€ç´¢æ•ˆæœ
    
    Returns:
        str: åŸºäºåŒ»å­¦çŸ¥è¯†åº“æ£€ç´¢çš„è¯¦ç»†ä¸“ä¸šç­”æ¡ˆ
            - å†…å®¹å‡†ç¡®å¯é ï¼Œæ¥æºäºæƒå¨åŒ»å­¦èµ„æ–™
            - ç»“æ„åŒ–ç»„ç»‡ä¿¡æ¯ï¼Œæ˜“äºç†è§£
            - åŒ…å«ç—‡çŠ¶ã€è¯Šæ–­ã€æ²»ç–—ç­‰å…¨æ–¹ä½ä¿¡æ¯
            - ä½¿ç”¨ä¸“ä¸šåŒ»å­¦æœ¯è¯­ï¼ŒåŒæ—¶å…¼é¡¾é€šä¿—æ˜“æ‡‚
            - ğŸ†• å¦‚æœ‰å›¾åƒåˆ†æï¼Œä¼šæ•´åˆå½±åƒä¿¡æ¯ä¸æ–‡çŒ®çŸ¥è¯†
    
    âš ï¸ é‡è¦æé†’ï¼š
    - æœ¬å·¥å…·æä¾›çš„ä¿¡æ¯ä»…ä¾›åŒ»å­¦ç§‘æ™®å’Œå‚è€ƒ
    - ä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­å’Œæ²»ç–—å»ºè®®
    - å¦‚æœ‰å¥åº·é—®é¢˜ï¼Œè¯·åŠæ—¶å°±åŒ»å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
    - ç”¨è¯è¯·éµåŒ»å˜±ï¼Œä¸å¯è‡ªè¡Œè¯Šæ–­ç”¨è¯
    
    Example:
        question = "ä»‹ç»ä¸€ä¸‹é£Ÿç®¡ç™Œçš„ç—‡çŠ¶"
        image_analysis = "CTæ£€æŸ¥æ˜¾ç¤ºé£Ÿç®¡å£å¢åšï¼Œç®¡è…”ç‹­çª„..."
        è¿”å›: åŸºäºæ–‡çŒ®å’Œå½±åƒçš„ç»¼åˆé£Ÿç®¡ç™Œç—‡çŠ¶åˆ†æ
    """
    if not qa_system_available:
        error_msg = "QAæ£€ç´¢ç³»ç»Ÿä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥DASHSCOPE_API_KEYç¯å¢ƒå˜é‡æˆ–ç›¸å…³ä¾èµ–"
        logger.error(error_msg)
        return error_msg
    
    try:
        # å¼ºåˆ¶å°†è¾“å…¥å‚æ•°è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…æ¨¡å‹æŠ¥ contents ç±»å‹é”™è¯¯
        try:
            if not isinstance(question, str):
                import json as _json
                question = _json.dumps(question, ensure_ascii=False)
        except Exception:
            question = str(question)

        try:
            if image_analysis is None:
                image_analysis = ""
            elif not isinstance(image_analysis, str):
                import json as _json
                image_analysis = _json.dumps(image_analysis, ensure_ascii=False)
        except Exception:
            image_analysis = str(image_analysis)

        logger.info(f"medical_qa_search called with question: {question}")
        logger.info(f"ğŸ“‹ å‚æ•°çŠ¶æ€æ£€æŸ¥:")
        try:
            logger.info(f"  - question: '{question}' (é•¿åº¦: {len(question)})")
        except Exception:
            logger.info("  - question: <æ— æ³•è®¡ç®—é•¿åº¦>")
        try:
            logger.info(f"  - image_analysis: {'å­˜åœ¨' if image_analysis else 'ç©º'} (é•¿åº¦: {len(image_analysis)}, ç±»å‹: {type(image_analysis)})")
            logger.info(f"  - image_analysiså†…å®¹é¢„è§ˆ: '{image_analysis[:100]}...' " if len(image_analysis) > 100 else f"  - image_analysiså®Œæ•´å†…å®¹: '{image_analysis}'")
        except Exception:
            logger.info("  - image_analysis: <æ— æ³•è®¡ç®—æˆ–éå­—ç¬¦ä¸²ç±»å‹>")
        
        # ç®€åŒ–æŸ¥è¯¢å¤„ç†ï¼šç›´æ¥ä½¿ç”¨å›¾åƒåˆ†æå†…å®¹ï¼Œè·³è¿‡å…³é”®è¯æå–AI
        enhanced_question = question
        
        if image_analysis and image_analysis.strip():
            logger.info(f"ğŸ–¼ï¸ æ£€æµ‹åˆ°å›¾åƒåˆ†æå†…å®¹ï¼Œç›´æ¥æ•´åˆåˆ°æŸ¥è¯¢ä¸­")
            # ç›´æ¥å°†å›¾åƒåˆ†æå†…å®¹æ·»åŠ åˆ°æŸ¥è¯¢ä¸­ï¼Œä¸è°ƒç”¨é¢å¤–çš„å…³é”®è¯æå–AI
            enhanced_question = f"{question} [åŒ»ç–—å›¾åƒåˆ†æ: {image_analysis[:500]}]"  # é™åˆ¶é•¿åº¦é¿å…è¿‡é•¿
            logger.info(f"âš¡ å¿«é€Ÿæ•´åˆæŸ¥è¯¢å®Œæˆ: {enhanced_question[:100]}...")
        else:
            logger.info(f"âš ï¸ æ— å›¾åƒåˆ†æå†…å®¹ï¼Œä½¿ç”¨æ ‡å‡†RAGæ£€ç´¢")
        
        # å¢å¼ºçš„RAGç¼“å­˜ç³»ç»Ÿ
        import hashlib
        import time
        query_hash = hashlib.md5(f"{enhanced_question}_{image_analysis}".encode('utf-8')).hexdigest()
        
        # åˆå§‹åŒ–å…¨å±€RAGç¼“å­˜
        if not hasattr(medical_qa_search, '_rag_cache'):
            medical_qa_search._rag_cache = {}
        
        # æ£€æŸ¥ç¼“å­˜
        rag_answer = None
        if query_hash in medical_qa_search._rag_cache:
            cache_entry = medical_qa_search._rag_cache[query_hash]
            if time.time() - cache_entry['timestamp'] < 7200:  # å»¶é•¿åˆ°2å°æ—¶ç¼“å­˜
                logger.info(f"âš¡ RAGç¼“å­˜å‘½ä¸­: {question[:50]}...")
                rag_answer = cache_entry['answer']
                # æ›´æ–°è®¿é—®æ—¶é—´
                cache_entry['last_accessed'] = time.time()
            else:
                del medical_qa_search._rag_cache[query_hash]
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œæ‰§è¡ŒRAGæ£€ç´¢
        if rag_answer is None:
            response = qa_graph.invoke({"question": enhanced_question})
            answer_obj = response.get("answer")
            try:
                rag_answer_raw = getattr(answer_obj, "content", answer_obj)
                if isinstance(rag_answer_raw, list):
                    rag_answer = "".join([
                        part.get("text", str(part)) if isinstance(part, dict) else str(part)
                        for part in rag_answer_raw
                    ])
                elif isinstance(rag_answer_raw, str):
                    rag_answer = rag_answer_raw
                else:
                    import json as _json
                    rag_answer = _json.dumps(rag_answer_raw, ensure_ascii=False)
            except Exception:
                rag_answer = str(getattr(answer_obj, "content", answer_obj))
            
            # ç¼“å­˜ç»“æœ
            medical_qa_search._rag_cache[query_hash] = {
                'answer': rag_answer,
                'timestamp': time.time(),
                'last_accessed': time.time(),
                'question_preview': question[:100]
            }
            
            # æ™ºèƒ½ç¼“å­˜æ¸…ç†ï¼šä¼˜å…ˆæ¸…ç†æœ€å°‘è®¿é—®çš„æ¡ç›®
            if len(medical_qa_search._rag_cache) > 100:  # å¢åŠ ç¼“å­˜å®¹é‡
                # æ¸…ç†è¿‡æœŸæ¡ç›®
                current_time = time.time()
                expired_keys = [k for k, v in medical_qa_search._rag_cache.items() 
                              if current_time - v['timestamp'] > 7200]
                for k in expired_keys:
                    del medical_qa_search._rag_cache[k]
                
                # å¦‚æœè¿˜æ˜¯å¤ªå¤šï¼Œæ¸…ç†æœ€å°‘è®¿é—®çš„
                if len(medical_qa_search._rag_cache) > 100:
                    oldest_key = min(medical_qa_search._rag_cache.keys(), 
                                   key=lambda k: medical_qa_search._rag_cache[k].get('last_accessed', 0))
                    del medical_qa_search._rag_cache[oldest_key]
            
            logger.info(f"ğŸ’¾ RAGç»“æœå·²ç¼“å­˜: {question[:50]}... (ç¼“å­˜å¤§å°: {len(medical_qa_search._rag_cache)})")
        
        # ç®€åŒ–å¤„ç†ï¼šç›´æ¥è¿”å›RAGç»“æœï¼Œè·³è¿‡å›¾åƒä¿¡æ¯æ•´åˆAI
        if image_analysis and image_analysis.strip():
            logger.info(f"âš¡ å›¾åƒå¢å¼ºRAGæŸ¥è¯¢å®Œæˆï¼Œç›´æ¥è¿”å›ç»“æœï¼ˆè·³è¿‡æ•´åˆAIä»¥æå‡é€Ÿåº¦ï¼‰")
            # åœ¨RAGç­”æ¡ˆå‰æ·»åŠ å›¾åƒåˆ†ææ‘˜è¦ï¼Œä½†ä¸è°ƒç”¨é¢å¤–çš„æ•´åˆAI
            image_summary = image_analysis[:200] + "..." if len(image_analysis) > 200 else image_analysis
            final_answer = f"ã€åŒ»ç–—å›¾åƒåˆ†æã€‘\n{image_summary}\n\nã€ä¸“ä¸šåŒ»å­¦çŸ¥è¯†ã€‘\n{rag_answer}\n\nâš ï¸ ä»¥ä¸Šä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿè¿›è¡Œç¡®è¯Šã€‚"
            return final_answer
        else:
            logger.info(f"âœ… æ ‡å‡†RAGæŸ¥è¯¢å®Œæˆ")
            return rag_answer
        
    except Exception as e:
        error_msg = f"åŒ»å­¦é—®ç­”æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        logger.error(f"medical_qa_search error: {error_msg}")
        return error_msg


@mcp.tool()
def get_hospital_info(cnName: str = "", address: str = "", enName: str = "", cnShort: str = "", hospitalType: str = "", level: str = "", ownership: str = "", pageSize: int = 10) -> str:
    """å…¨å›½åŒ»é™¢ä¿¡æ¯æŸ¥è¯¢å·¥å…·
    
    è¿™æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»é™¢ä¿¡æ¯æŸ¥è¯¢ç³»ç»Ÿï¼Œè¿æ¥å…¨å›½åŒ»é™¢æ•°æ®åº“ï¼Œæä¾›è¯¦ç»†çš„åŒ»é™¢ä¿¡æ¯æŸ¥è¯¢æœåŠ¡ã€‚
    æ”¯æŒå¤šç»´åº¦æœç´¢æ¡ä»¶ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿæ‰¾åˆ°åˆé€‚çš„åŒ»ç–—æœºæ„ã€‚
    
    ğŸ¥ æŸ¥è¯¢åŠŸèƒ½ï¼š
    - æ”¯æŒç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³Šæœç´¢
    - å¤šæ¡ä»¶ç»„åˆæŸ¥è¯¢
    - å®æ—¶è·å–æœ€æ–°åŒ»é™¢ä¿¡æ¯
    - æä¾›è¯¦ç»†åŒ»é™¢èµ„æ–™
    
    ğŸ“Š è¿”å›ä¿¡æ¯åŒ…æ‹¬ï¼š
    - åŒ»é™¢åŸºæœ¬ä¿¡æ¯ï¼ˆåç§°ã€åœ°å€ã€ç”µè¯ï¼‰
    - åŒ»é™¢è§„æ¨¡ï¼ˆåºŠä½æ•°ã€å‘˜å·¥æ•°ï¼‰
    - åŒ»é™¢ç­‰çº§å’Œæ€§è´¨
    - å»ºé™¢æ—¶é—´å’Œç®€ä»‹
    - å®˜æ–¹ç½‘ç«™
    
    Args:
        cnName (str, optional): åŒ»é™¢ä¸­æ–‡åç§°
            - æ”¯æŒæ¨¡ç³Šæœç´¢ï¼Œå¦‚è¾“å…¥"äººæ°‘åŒ»é™¢"å¯æ‰¾åˆ°æ‰€æœ‰åŒ…å«æ­¤å…³é”®è¯çš„åŒ»é™¢
            - ç¤ºä¾‹ï¼š"åŒ—äº¬åå’ŒåŒ»é™¢"ã€"ä¸Šæµ·ç¬¬ä¸€äººæ°‘åŒ»é™¢"
            - ç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶åŒ»é™¢åç§°
            
        address (str, optional): åŒ»é™¢åœ°å€æˆ–æ‰€åœ¨åœ°åŒº
            - æ”¯æŒçœå¸‚åŒºå¿çº§æœç´¢
            - ç¤ºä¾‹ï¼š"åŒ—äº¬å¸‚"ã€"ä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒº"ã€"å¹¿å·"
            - å¯ç”¨äºæŸ¥æ‰¾ç‰¹å®šåœ°åŒºçš„åŒ»é™¢
            
        enName (str, optional): åŒ»é™¢è‹±æ–‡åç§°
            - ç”¨äºæŸ¥è¯¢æœ‰è‹±æ–‡åç§°çš„åŒ»é™¢
            - ç¤ºä¾‹ï¼š"Peking Union Medical College Hospital"
            - ä¸»è¦ç”¨äºæŸ¥è¯¢å›½é™…åŒ–åŒ»é™¢æˆ–çŸ¥ååŒ»é™¢
            
        cnShort (str, optional): åŒ»é™¢ä¸­æ–‡ç®€ç§°æˆ–åˆ«å
            - åŒ»é™¢çš„ç®€ç§°æˆ–å¸¸ç”¨åˆ«å
            - ç¤ºä¾‹ï¼š"åå’Œ"ã€"301åŒ»é™¢"ã€"åè¥¿"
            - æ–¹ä¾¿ä½¿ç”¨åŒ»é™¢å¸¸ç”¨ç®€ç§°æŸ¥è¯¢
            
        hospitalType (str, optional): åŒ»é™¢ç±»å‹
            - å¯é€‰å€¼ï¼š"ç»¼åˆæ€§åŒ»é™¢"ã€"ä¸“ç§‘åŒ»é™¢"ã€"ä¸­åŒ»åŒ»é™¢"ã€"å¦‡å¹¼ä¿å¥é™¢"ç­‰
            - å¸®åŠ©æŸ¥æ‰¾ç‰¹å®šç±»å‹çš„åŒ»ç–—æœºæ„
            - ç¤ºä¾‹ï¼šæŸ¥æ‰¾"ä¸“ç§‘åŒ»é™¢"å¯æ‰¾åˆ°çœ¼ç§‘åŒ»é™¢ã€å¿ƒè¡€ç®¡åŒ»é™¢ç­‰
            
        level (str, optional): åŒ»é™¢ç­‰çº§
            - å¯é€‰å€¼ï¼š"ä¸‰çº§ç”²ç­‰"ã€"ä¸‰çº§ä¹™ç­‰"ã€"äºŒçº§ç”²ç­‰"ã€"äºŒçº§ä¹™ç­‰"ã€"ä¸€çº§ç”²ç­‰"ç­‰
            - ç”¨äºæŸ¥æ‰¾ç‰¹å®šç­‰çº§çš„åŒ»é™¢
            - ç¤ºä¾‹ï¼š"ä¸‰çº§ç”²ç­‰"æŸ¥æ‰¾æœ€é«˜ç­‰çº§åŒ»é™¢
            
        ownership (str, optional): åŒ»é™¢æ€§è´¨
            - å¯é€‰å€¼ï¼š"å…¬ç«‹"ã€"ç§ç«‹"ã€"æ°‘è¥"ã€"åˆèµ„"ç­‰
            - ç”¨äºåŒºåˆ†åŒ»é™¢çš„æ‰€æœ‰åˆ¶æ€§è´¨
            - ç¤ºä¾‹ï¼š"å…¬ç«‹"æŸ¥æ‰¾å…¬ç«‹åŒ»é™¢
            
        pageSize (int, optional): æ¯é¡µæ˜¾ç¤ºçš„åŒ»é™¢æ•°é‡
            - é»˜è®¤å€¼ï¼š10
            - èŒƒå›´ï¼š1-50
            - æ§åˆ¶è¿”å›ç»“æœçš„æ•°é‡ï¼Œé¿å…ä¿¡æ¯è¿‡è½½
    
    Returns:
        str: æ ¼å¼åŒ–çš„åŒ»é™¢ä¿¡æ¯åˆ—è¡¨
            åŒ…å«ä»¥ä¸‹è¯¦ç»†ä¿¡æ¯ï¼š
            - åŒ»é™¢ä¸­æ–‡åç§°å’Œè‹±æ–‡åç§°
            - åŒ»é™¢åœ°å€å’Œè”ç³»ç”µè¯
            - åŒ»é™¢ç±»å‹ã€ç­‰çº§å’Œæ€§è´¨
            - åºŠä½æ•°å’Œå‘˜å·¥æ•°
            - å»ºé™¢æ—¶é—´å’ŒåŒ»é™¢ç®€ä»‹
            - å®˜æ–¹ç½‘ç«™
            
            å¦‚æœæœªæ‰¾åˆ°åŒ¹é…çš„åŒ»é™¢ï¼Œä¼šè¿”å›ç›¸åº”çš„æç¤ºä¿¡æ¯ã€‚
    
    ğŸ¯ ä½¿ç”¨åœºæ™¯ï¼š
    - å°±åŒ»æ¨èï¼šæ ¹æ®åœ°åŒºå’Œä¸“ç§‘æŸ¥æ‰¾åˆé€‚åŒ»é™¢
    - åŒ»é™¢å¯¹æ¯”ï¼šæ¯”è¾ƒä¸åŒåŒ»é™¢çš„è§„æ¨¡å’Œç­‰çº§
    - è½¬é™¢å‚è€ƒï¼šæŸ¥æ‰¾ä¸Šçº§åŒ»é™¢æˆ–ä¸“ç§‘åŒ»é™¢
    - åŒ»ç–—èµ„æºè°ƒç ”ï¼šäº†è§£æŸåœ°åŒºåŒ»ç–—èµ„æºåˆ†å¸ƒ
    
    ğŸ’¡ æŸ¥è¯¢æŠ€å·§ï¼š
    1. å•æ¡ä»¶æŸ¥è¯¢ï¼šåªå¡«å†™ä¸€ä¸ªå‚æ•°è¿›è¡Œå®½æ³›æœç´¢
    2. ç»„åˆæŸ¥è¯¢ï¼šç»“åˆå¤šä¸ªæ¡ä»¶ç²¾ç¡®æŸ¥æ‰¾
    3. åœ°åŒºæŸ¥è¯¢ï¼šä½¿ç”¨addresså‚æ•°æŸ¥æ‰¾æœ¬åœ°åŒ»é™¢
    4. ç­‰çº§ç­›é€‰ï¼šä½¿ç”¨levelå‚æ•°æŸ¥æ‰¾é«˜ç­‰çº§åŒ»é™¢
    
    Example:
        # æŸ¥æ‰¾åŒ—äº¬çš„ä¸‰çº§ç”²ç­‰åŒ»é™¢
        cnName="", address="åŒ—äº¬", level="ä¸‰çº§ç”²ç­‰"
        
        # æŸ¥æ‰¾åå’ŒåŒ»é™¢çš„è¯¦ç»†ä¿¡æ¯
        cnName="åå’ŒåŒ»é™¢"
        
        # æŸ¥æ‰¾ä¸Šæµ·çš„ä¸“ç§‘åŒ»é™¢
        address="ä¸Šæµ·", hospitalType="ä¸“ç§‘åŒ»é™¢"
    """
    try:
        # API URL
        url = "http://localhost:48080/admin-api/datamanagement/hospital/page"
        
        # è¯·æ±‚å‚æ•°
        params = {
            "pageSize": pageSize
        }
        
        # æ·»åŠ æ‰€æœ‰æœç´¢æ¡ä»¶åˆ°å‚æ•°ä¸­
        if cnName:
            params["cnName"] = cnName
        if address:
            params["address"] = address
        if enName:
            params["enName"] = enName
        if cnShort:
            params["cnShort"] = cnShort
        if hospitalType:
            params["hospitalType"] = hospitalType
        if level:
            params["level"] = level
        if ownership:
            params["ownership"] = ownership
        
        # è¯·æ±‚å¤´
        headers = {
            "tenant-id": "1",
            "Content-Type": "application/json"
        }
        
        logger.info(f"get_hospital_info called with cnName='{cnName}', address='{address}', enName='{enName}', cnShort='{cnShort}', hospitalType='{hospitalType}', level='{level}', ownership='{ownership}', pageSize={pageSize}")
        
        # å‘é€HTTPè¯·æ±‚
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        
        # è§£æå“åº”æ•°æ®
        data = response.json()
        
        if data.get("code") == 0:
            hospital_list = data.get("data", {}).get("list", [])
            total = data.get("data", {}).get("total", 0)
            
            if hospital_list:
                # æ ¼å¼åŒ–åŒ»é™¢ä¿¡æ¯
                search_conditions = []
                if cnName:
                    search_conditions.append(f"åŒ»é™¢åç§°: {cnName}")
                if address:
                    search_conditions.append(f"åœ°å€: {address}")
                if enName:
                    search_conditions.append(f"è‹±æ–‡åç§°: {enName}")
                if cnShort:
                    search_conditions.append(f"ä¸­æ–‡ç®€ç§°: {cnShort}")
                if hospitalType:
                    search_conditions.append(f"åŒ»é™¢ç±»å‹: {hospitalType}")
                if level:
                    search_conditions.append(f"åŒ»é™¢ç­‰çº§: {level}")
                if ownership:
                    search_conditions.append(f"åŒ»é™¢æ€§è´¨: {ownership}")
                
                result_info = f"æ‰¾åˆ° {total} å®¶åŒ»é™¢"
                if search_conditions:
                    search_info = "ã€".join(search_conditions)
                    result_info += f"ï¼ˆæœç´¢æ¡ä»¶ï¼š{search_info}ï¼‰"
                result_info += "ï¼š\n\n"
                
                for hospital in hospital_list:
                    result_info += f"åŒ»é™¢ä¸­æ–‡åç§°ï¼š{hospital.get('cnName', 'æœªçŸ¥')}\n"
                    result_info += f"åŒ»é™¢ä¸­æ–‡ç¼©å†™åç§°ï¼š{hospital.get('cnShort', 'æœªçŸ¥')}\n"
                    result_info += f"åŒ»é™¢è‹±æ–‡åç§°ï¼š{hospital.get('enName', 'æœªçŸ¥')}\n"
                    result_info += f"åŒ»é™¢ç±»å‹ï¼š{hospital.get('hospitalType', 'æœªçŸ¥')}\n"
                    result_info += f"åŒ»é™¢ç­‰çº§ï¼š{hospital.get('level', 'æœªçŸ¥')}\n"
                    result_info += f"æ‰€æœ‰åˆ¶ï¼š{hospital.get('ownership', 'æœªçŸ¥')}\n"
                    result_info += f"åœ°å€ï¼š{hospital.get('address', 'æœªçŸ¥')}\n"
                    result_info += f"ç”µè¯ï¼š{hospital.get('phone', 'æœªæä¾›')}\n"
                    result_info += f"åºŠä½æ•°ï¼š{hospital.get('bedCount', 0)}\n"
                    result_info += f"å‘˜å·¥æ•°ï¼š{hospital.get('staffCount', 0)}\n"
                    if hospital.get('establishedYear'):
                        result_info += f"å»ºé™¢æ—¶é—´ï¼š{hospital.get('establishedYear')}å¹´\n"
                    if hospital.get('introduction'):
                        intro = hospital.get('introduction', '')
                        result_info += f"åŒ»é™¢ç®€ä»‹ï¼š{intro}...\n"
                    result_info += f"ç½‘ç«™ï¼š{hospital.get('website', 'æœªæä¾›')}\n"
                    result_info += "\n" + "="*50 + "\n\n"
                
                logger.info(f"get_hospital_info success: found {total} hospitals")
                return result_info
            else:
                search_conditions = []
                if cnName:
                    search_conditions.append(f"åŒ»é™¢åç§°: {cnName}")
                if address:
                    search_conditions.append(f"åœ°å€: {address}")
                if enName:
                    search_conditions.append(f"è‹±æ–‡åç§°: {enName}")
                if cnShort:
                    search_conditions.append(f"ä¸­æ–‡ç®€ç§°: {cnShort}")
                if hospitalType:
                    search_conditions.append(f"åŒ»é™¢ç±»å‹: {hospitalType}")
                if level:
                    search_conditions.append(f"åŒ»é™¢ç­‰çº§: {level}")
                if ownership:
                    search_conditions.append(f"åŒ»é™¢æ€§è´¨: {ownership}")
                search_text = "ã€".join(search_conditions) if search_conditions else "æ— ç‰¹å®šæ¡ä»¶"
                
                result = f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åŒ»é™¢ï¼ˆæœç´¢æ¡ä»¶ï¼š{search_text}ï¼‰"
                logger.info(f"get_hospital_info: no hospitals found")
                return result
        else:
            error_msg = f"APIè¿”å›é”™è¯¯ï¼š{data.get('msg', 'æœªçŸ¥é”™è¯¯')}"
            logger.error(f"get_hospital_info API error: {error_msg}")
            return error_msg
            
    except requests.exceptions.RequestException as e:
        error_msg = f"ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼š{str(e)}"
        logger.error(f"get_hospital_info network error: {error_msg}")
        return error_msg
    except json.JSONDecodeError as e:
        error_msg = f"JSONè§£æå¤±è´¥ï¼š{str(e)}"
        logger.error(f"get_hospital_info JSON error: {error_msg}")
        return error_msg
    except Exception as e:
        error_msg = f"è·å–åŒ»é™¢ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        logger.error(f"get_hospital_info unexpected error: {error_msg}")
        return error_msg

# å¯åŠ¨MCPæœåŠ¡å™¨
if __name__ == "__main__":

    # å¯åŠ¨æœåŠ¡å™¨ï¼Œç»‘å®šåˆ°æ‰€æœ‰æ¥å£ä»¥é¿å…ç½‘ç»œé—®é¢˜
    logger.info("æ­£åœ¨å¯åŠ¨MCPæœåŠ¡å™¨...")
    try:
        mcp.run(
            transport="sse",
            host="0.0.0.0",  # ç»‘å®šåˆ°æ‰€æœ‰æ¥å£
            port=18002  # ä½¿ç”¨æ›´é«˜ç«¯å£é¿å…å†²çª
        )
    except Exception as e:
        logger.error(f"MCPæœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)
