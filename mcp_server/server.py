from fastmcp import FastMCP
import sys
import logging
from datetime import datetime, timedelta
import requests
import json
import os
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ  get_db_qa ç›¸å…³çš„å¯¼å…¥
from typing_extensions import List, TypedDict
from langchain_core.documents import Document
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langgraph.constants import START
from langgraph.graph import StateGraph
from langchain.chat_models import init_chat_model
from rerankers import Reranker

# ç¦ç”¨Hugging Faceç¬¦å·é“¾æ¥è­¦å‘Š
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

# è®¾ç½®è¯¦ç»†çš„æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("FastMCP-Server")

# åˆ›å»ºMCPæœåŠ¡å™¨
mcp = FastMCP(
    name="medical_assistant_tools",
    instructions="""
    ä¸“ä¸šåŒ»ç–—åŠ©æ‰‹å·¥å…·æœåŠ¡å™¨ - æä¾›å…¨é¢çš„åŒ»ç–—ä¿¡æ¯æŸ¥è¯¢å’Œè¾…åŠ©åŠŸèƒ½

    ğŸ¥ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼š
    
    1. ã€åŒ»å­¦çŸ¥è¯†é—®ç­”ã€‘- medical_qa_search
       - åŸºäºä¸“ä¸šåŒ»å­¦çŸ¥è¯†åº“çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
       - æ”¯æŒç–¾ç—…ç—‡çŠ¶ã€è¯Šæ–­ã€æ²»ç–—æ–¹æ³•ç­‰å…¨æ–¹ä½æŸ¥è¯¢
       - ä½¿ç”¨å…ˆè¿›çš„æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œæä¾›å‡†ç¡®å¯é çš„åŒ»å­¦ä¿¡æ¯
       - é€‚ç”¨åœºæ™¯ï¼šç–¾ç—…ç§‘æ™®ã€æ²»ç–—æŒ‡å—ã€åŒ»å­¦æœ¯è¯­è§£é‡Šç­‰
    
    2. ã€åŒ»é™¢ä¿¡æ¯æŸ¥è¯¢ã€‘- get_hospital_info
       - å…¨å›½åŒ»é™¢æ•°æ®åº“æŸ¥è¯¢æœåŠ¡
       - æ”¯æŒå¤šç»´åº¦æœç´¢ï¼šåŒ»é™¢åç§°ã€åœ°å€ã€ç­‰çº§ã€ç±»å‹ç­‰
       - æä¾›è¯¦ç»†åŒ»é™¢ä¿¡æ¯ï¼šè”ç³»æ–¹å¼ã€è§„æ¨¡ã€æ€§è´¨ã€ç®€ä»‹ç­‰
       - é€‚ç”¨åœºæ™¯ï¼šå°±åŒ»æ¨èã€åŒ»é™¢å¯¹æ¯”ã€åŒ»ç–—èµ„æºæŸ¥è¯¢ç­‰
    
    3. ã€æ—¶é—´è¾…åŠ©å·¥å…·ã€‘
       - get_current_date: è·å–å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYYå¹´MMæœˆDDæ—¥
       - get_current_time: è·å–å½“å‰æ—¶é—´ï¼Œæ ¼å¼ä¸ºHH:MM:SS
       - é€‚ç”¨åœºæ™¯ï¼šåŒ»ç–—è®°å½•æ—¶é—´æˆ³ã€é¢„çº¦æ—¶é—´å‚è€ƒç­‰

    ğŸ¯ ä½¿ç”¨æŒ‡å—ï¼š
    - åŒ»å­¦é—®ç­”ï¼šç›´æ¥è¾“å…¥åŒ»å­¦ç›¸å…³é—®é¢˜ï¼Œå¦‚"ç³–å°¿ç—…çš„ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ"
    - åŒ»é™¢æŸ¥è¯¢ï¼šå¯æŒ‰åŒ»é™¢åç§°ã€åœ°åŒºã€ç­‰çº§ç­‰æ¡ä»¶æœç´¢
    - æ—¶é—´æŸ¥è¯¢ï¼šæ— éœ€å‚æ•°ï¼Œç›´æ¥è·å–å½“å‰æ—¥æœŸæ—¶é—´
    
    âš ï¸ é‡è¦è¯´æ˜ï¼š
    - æ‰€æœ‰åŒ»å­¦ä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®
    - å»ºè®®åœ¨ä¸“ä¸šåŒ»ç”ŸæŒ‡å¯¼ä¸‹è¿›è¡Œè¯Šæ–­å’Œæ²»ç–—
    - åŒ»é™¢ä¿¡æ¯æ¥æºäºå…¬å¼€æ•°æ®åº“ï¼Œå¦‚æœ‰å˜åŠ¨è¯·ä»¥å®˜æ–¹ä¸ºå‡†
    """,
)

# åˆå§‹åŒ–QAæ£€ç´¢ç³»ç»Ÿ
try:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.warning("OPENAI_API_KEY not found, QA retrieval system will not be available")
        qa_system_available = False
    else:
        # åˆå§‹åŒ–OpenAIæ¨¡å‹
        llm = init_chat_model("gpt-4o-mini", model_provider="openai")
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
        vector_store = Chroma(
            collection_name="openai_collection_qa_enhanced_docs",  # QAå¢å¼ºçš„é›†åˆåç§°
            embedding_function=embeddings,
            persist_directory="./chroma_langchain_db",  # Where to save data locally, remove if not necessary
        )
        
        # åˆå§‹åŒ–OpenAI rerankeræ¨¡å‹ï¼ˆä½¿ç”¨RankGPTï¼‰
        reranker = Reranker("rankgpt", api_key=api_key)
        
        # ä¸ºHyDEï¼ˆå‡è®¾æ€§æ–‡æ¡£åµŒå…¥ï¼‰åˆ›å»ºä¸€ä¸ªæç¤º
        hyde_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»å­¦ä¸“å®¶ã€‚åŸºäºç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªè¯¦ç»†ã€å‡†ç¡®çš„å‡è®¾æ€§ç­”æ¡ˆæ–‡æ¡£ï¼Œè¿™ä¸ªç­”æ¡ˆåº”è¯¥ï¼š

            1. ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
            2. åŒ…å«ç›¸å…³çš„åŒ»å­¦æœ¯è¯­å’Œä¸“ä¸šè¡¨è¿°
            3. ç»“æ„åŒ–åœ°ç»„ç»‡ä¿¡æ¯ï¼ˆå¦‚ç—‡çŠ¶ã€è¯Šæ–­ã€æ²»ç–—ç­‰ï¼‰
            4. è¯­è¨€é£æ ¼ç±»ä¼¼äºåŒ»å­¦æŒ‡å—ã€æ•™ç§‘ä¹¦æˆ–ä¸“ä¸šæ–‡çŒ®
            5. å†…å®¹è¯¦å®ï¼Œæ¶µç›–é—®é¢˜çš„å„ä¸ªæ–¹é¢

            è¯·æ³¨æ„ï¼šè¿™ä¸ªç­”æ¡ˆå°†ç”¨äºæ£€ç´¢ç›¸ä¼¼çš„åŒ»å­¦æ–‡æ¡£ï¼Œå› æ­¤è¯·å°½å¯èƒ½ä½¿ç”¨æ ‡å‡†çš„åŒ»å­¦è¡¨è¿°å’Œæœ¯è¯­ã€‚

            ç”¨æˆ·é—®é¢˜ï¼š{question}

            å‡è®¾æ€§ç­”æ¡ˆï¼š""",
            input_variables=["question"],
        )

        answer_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ç§‘æ™®åŠ©æ‰‹ï¼Œé€šè¿‡ä»æ–‡æ¡£ä¸­æå–ä¿¡æ¯æ¥ä¸ºç”¨æˆ·å…¨é¢ç§‘æ™®çŸ¥è¯†ï¼Œæ–¹æ–¹é¢é¢éƒ½è¦è®²åˆ°ã€‚åªèƒ½ä½¿ç”¨æä¾›çš„æ–‡æ¡£å†…å®¹æ¥å›ç­”é—®é¢˜ï¼Œä¸èƒ½ä½¿ç”¨å…¶ä»–ä¿¡æ¯ã€‚

        ä¸Šä¸‹æ–‡ï¼š
        {context}

        é—®é¢˜ï¼š{question}

        ç­”æ¡ˆï¼š""",
            input_variables=["context", "question"]
        )

        class State(TypedDict):  # å®šä¹‰çŠ¶æ€ç±»å‹
            question: str
            context: List[Document]
            reranked_context: List[Document]  # æ·»åŠ é‡æ’åºåçš„æ–‡æ¡£å­—æ®µ
            answer: str

        def retrieve(state: State):  # QAå¢å¼ºçš„æ–‡æ¡£æ£€ç´¢
            question = state["question"]
            logger.info(f"ğŸ” å¼€å§‹QAå¢å¼ºæ£€ç´¢ï¼Œé—®é¢˜ï¼š{question}")

            # é˜¶æ®µ1ï¼šç›´æ¥æ£€ç´¢QAæ–‡æ¡£ï¼ˆä½¿ç”¨é—®é¢˜æœ¬èº«ï¼‰
            logger.info("ğŸ“‹ é˜¶æ®µ1ï¼šæ£€ç´¢QAé—®ç­”å¯¹...")
            all_qa_docs = vector_store.similarity_search(question, k=20)
            qa_docs = [doc for doc in all_qa_docs if doc.metadata.get('content_type') in ['generated_qa', 'target_qa']][:8]
            logger.info(f"æ‰¾åˆ° {len(qa_docs)} ä¸ªQAæ–‡æ¡£")

            # é˜¶æ®µ2ï¼šä½¿ç”¨HyDEæ£€ç´¢åŸå§‹æ–‡æ¡£
            logger.info("ğŸ“„ é˜¶æ®µ2ï¼šä½¿ç”¨HyDEæ£€ç´¢åŸå§‹æ–‡æ¡£...")
            hyde_chain = hyde_prompt | llm
            hypothetical_answer = hyde_chain.invoke({"question": question})
            logger.info(f"å‡è®¾æ€§ç­”æ¡ˆ (HyDE): {hypothetical_answer.content[:100]}...")

            # æ£€ç´¢åŸå§‹æ–‡æ¡£ï¼ˆæ’é™¤QAæ–‡æ¡£ï¼‰
            all_original_docs = vector_store.similarity_search(hypothetical_answer.content, k=20)
            original_docs = [doc for doc in all_original_docs if
                             doc.metadata.get('content_type') not in ['generated_qa', 'target_qa']][:8]
            logger.info(f"æ‰¾åˆ° {len(original_docs)} ä¸ªåŸå§‹æ–‡æ¡£")

            # åˆå¹¶ç»“æœï¼ŒQAæ–‡æ¡£ä¼˜å…ˆ
            all_docs = qa_docs + original_docs

            # å»é‡ï¼ˆåŸºäºå†…å®¹ç›¸ä¼¼æ€§ï¼‰
            unique_docs = []
            seen_content = set()

            for doc in all_docs:
                # ä½¿ç”¨å†…å®¹çš„å‰100ä¸ªå­—ç¬¦ä½œä¸ºå»é‡ä¾æ®
                content_key = doc.page_content[:100]
                if content_key not in seen_content:
                    seen_content.add(content_key)
                    unique_docs.append(doc)

            logger.info(f"ğŸ¯ æ£€ç´¢å®Œæˆï¼Œå…±è·å¾— {len(unique_docs)} ä¸ªå”¯ä¸€æ–‡æ¡£ï¼ˆQA: {len(qa_docs)}, åŸå§‹: {len(original_docs)}ï¼‰")

            # è¿”å›æœ€å¤š15ä¸ªæ–‡æ¡£ç”¨äºé‡æ’åº
            return {"context": unique_docs[:15]}

        def rerank(state: State):  # ä½¿ç”¨OpenAIçš„RankGPTå¯¹æ£€ç´¢åˆ°çš„æ–‡æ¡£è¿›è¡Œé‡æ’åº
            query = state["question"]
            docs = state["context"]

            # ä¸ºrerankerå‡†å¤‡æ–‡æ¡£å†…å®¹
            doc_texts = [doc.page_content for doc in docs]

            # ä½¿ç”¨RankGPTè¿›è¡Œé‡æ’åº
            try:
                results = reranker.rank(query=query, docs=doc_texts)

                # æ ¹æ®é‡æ’åºç»“æœé‡æ–°æ’åˆ—æ–‡æ¡£
                reranked_docs = []

                # è·å–å‰10ä¸ªç»“æœ
                top_results = results.top_k(10)

                for i, result in enumerate(top_results):
                    # å°è¯•å¤šç§æ–¹å¼è·å–æ–‡æ¡£ç´¢å¼•
                    doc_index = None

                    # æ–¹æ³•1: é€šè¿‡documentå¯¹è±¡çš„textåŒ¹é…åŸå§‹æ–‡æ¡£
                    if hasattr(result, 'document') and hasattr(result.document, 'text'):
                        result_text = result.document.text
                        for j, doc in enumerate(docs):
                            if doc.page_content == result_text:
                                doc_index = j
                                break

                    # æ–¹æ³•2: é€šè¿‡doc_idåŒ¹é…
                    if doc_index is None:
                        if hasattr(result, 'doc_id'):
                            try:
                                doc_index = int(result.doc_id)
                            except (ValueError, TypeError):
                                pass
                        elif hasattr(result, 'document') and hasattr(result.document, 'doc_id'):
                            try:
                                doc_index = int(result.document.doc_id)
                            except (ValueError, TypeError):
                                pass

                    # æ–¹æ³•3: æ ¹æ®æ–‡æ¡£å†…å®¹åŒ¹é…
                    if doc_index is None:
                        # å°è¯•é€šè¿‡resultçš„textå±æ€§åŒ¹é…
                        if hasattr(result, 'text'):
                            result_text = result.text
                        elif hasattr(result, 'document') and hasattr(result.document, 'text'):
                            result_text = result.document.text
                        else:
                            result_text = str(result)

                        for j, doc in enumerate(docs):
                            if doc.page_content.strip() == result_text.strip():
                                doc_index = j
                                break

                    # æ–¹æ³•4: å¤‡é€‰æ–¹æ¡ˆï¼Œä½¿ç”¨é¡ºåºç´¢å¼•
                    if doc_index is None:
                        doc_index = i

                    # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆå¹¶æ·»åŠ æ–‡æ¡£
                    if doc_index is not None and 0 <= doc_index < len(docs):
                        if docs[doc_index] not in reranked_docs:  # é¿å…é‡å¤
                            reranked_docs.append(docs[doc_index])

                # å¦‚æœé‡æ’åºçš„æ–‡æ¡£æ•°é‡ä¸è¶³ï¼Œè¡¥å……å‰©ä½™æ–‡æ¡£
                if len(reranked_docs) < min(10, len(docs)):
                    for doc in docs:
                        if doc not in reranked_docs and len(reranked_docs) < 10:
                            reranked_docs.append(doc)

                logger.info(f"é‡æ’åºå®Œæˆï¼Œä» {len(docs)} ä¸ªæ–‡æ¡£ä¸­é€‰æ‹©äº† {len(reranked_docs)} ä¸ª")

                # åˆ†æé‡æ’åºåçš„æ–‡æ¡£ç±»å‹
                qa_count = len(
                    [doc for doc in reranked_docs[:10] if doc.metadata.get('content_type') in ['generated_qa', 'target_qa']])
                original_count = len(reranked_docs[:10]) - qa_count
                logger.info(f"ğŸ“Š é‡æ’åºç»“æœï¼šQAæ–‡æ¡£ {qa_count} ä¸ªï¼ŒåŸå§‹æ–‡æ¡£ {original_count} ä¸ª")

                return {"reranked_context": reranked_docs[:10]}  # ç¡®ä¿è¿”å›æœ€å¤š10ä¸ªæ–‡æ¡£

            except Exception as e:
                logger.error(f"é‡æ’åºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                logger.info("ä½¿ç”¨åŸå§‹æ–‡æ¡£é¡ºåºä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
                # å¦‚æœé‡æ’åºå¤±è´¥ï¼Œè¿”å›å‰10ä¸ªåŸå§‹æ–‡æ¡£
                return {"reranked_context": docs[:10]}

        def generate(state: State):  # QAå¢å¼ºçš„ç­”æ¡ˆç”Ÿæˆ
            # ä½¿ç”¨é‡æ’åºåçš„æ–‡æ¡£ï¼Œæ™ºèƒ½ç»„ç»‡QAå’ŒåŸå§‹æ–‡æ¡£å†…å®¹
            max_doc_length = 1200  # æ¯ä¸ªæ–‡æ¡£æœ€å¤§å­—ç¬¦æ•°
            max_total_length = 8000  # æ€»ä¸Šä¸‹æ–‡æœ€å¤§å­—ç¬¦æ•°

            formatted_docs = []
            total_length = 0
            qa_count = 0
            original_count = 0

            for i, doc in enumerate(state["reranked_context"], 1):
                content_type = doc.metadata.get('content_type', 'unknown')

                # æ ¼å¼åŒ–æ–‡æ¡£å†…å®¹ï¼ŒåŒºåˆ†QAå’ŒåŸå§‹æ–‡æ¡£
                if content_type in ['generated_qa', 'target_qa']:
                    qa_count += 1
                    doc_header = f"ã€QAé—®ç­”å¯¹ {qa_count}ã€‘"
                    if content_type == 'target_qa':
                        doc_header += "ï¼ˆä¸“ä¸šçŸ¥è¯†åº“ï¼‰"
                    elif content_type == 'generated_qa':
                        doc_header += f"ï¼ˆæ¥æºï¼š{doc.metadata.get('source_file', 'æœªçŸ¥')}ï¼‰"
                else:
                    original_count += 1
                    file_type = doc.metadata.get('file_type', 'unknown')
                    source_file = doc.metadata.get('source_file', 'æœªçŸ¥')
                    doc_header = f"ã€åŸå§‹æ–‡æ¡£ {original_count}ã€‘ï¼ˆ{file_type.upper()}ï¼š{source_file}ï¼‰"

                # æˆªæ–­æ–‡æ¡£å†…å®¹
                doc_content = doc.page_content[:max_doc_length]
                formatted_content = f"{doc_header}\n{doc_content}"

                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ€»é•¿åº¦é™åˆ¶
                content_with_separator = formatted_content + "\n\n"
                if total_length + len(content_with_separator) <= max_total_length:
                    formatted_docs.append(formatted_content)
                    total_length += len(content_with_separator)
                else:
                    # å¦‚æœä¼šè¶…è¿‡é™åˆ¶ï¼Œæ·»åŠ æˆªæ–­çš„å†…å®¹
                    remaining_space = max_total_length - total_length - len(doc_header) - 4  # 4 for "\n...\n\n"
                    if remaining_space > 100:
                        truncated_content = doc_content[:remaining_space] + "..."
                        formatted_content = f"{doc_header}\n{truncated_content}"
                        formatted_docs.append(formatted_content)
                    break

            docs_content = "\n\n".join(formatted_docs)
            logger.info(f"ğŸ’¡ ç”Ÿæˆç­”æ¡ˆï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡ï¼š{len(docs_content)} å­—ç¬¦ï¼ˆQAæ–‡æ¡£: {qa_count}, åŸå§‹æ–‡æ¡£: {original_count}ï¼‰")

            messages = answer_prompt.invoke({"question": state["question"], "context": docs_content})
            response = llm.invoke(messages)
            return {"answer": response}

        # æ„å»ºçŠ¶æ€å›¾
        graph_builder = StateGraph(State)
        graph_builder.add_node("retrieve", retrieve)
        graph_builder.add_node("rerank", rerank)
        graph_builder.add_node("generate", generate)
        graph_builder.add_edge(START, "retrieve")
        graph_builder.add_edge("retrieve", "rerank")
        graph_builder.add_edge("rerank", "generate")
        qa_graph = graph_builder.compile()
        
        qa_system_available = True
        logger.info("QAæ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        
except Exception as e:
    logger.error(f"QAæ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    qa_system_available = False

# MCPå·¥å…·
@mcp.tool()
def get_current_date() -> str:
    """è·å–å½“å‰ç³»ç»Ÿæ—¥æœŸ
    
    è¿™ä¸ªå·¥å…·ç”¨äºè·å–å½“å‰çš„ç³»ç»Ÿæ—¥æœŸï¼Œè¿”å›ä¸­æ–‡æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²ã€‚
    
    ğŸ“… åŠŸèƒ½è¯´æ˜ï¼š
    - è·å–å®æ—¶çš„å½“å‰æ—¥æœŸ
    - è¿”å›æ ¼å¼ï¼šYYYYå¹´MMæœˆDDæ—¥ï¼ˆå¦‚ï¼š2024å¹´12æœˆ19æ—¥ï¼‰
    - åŸºäºç³»ç»Ÿæœ¬åœ°æ—¶é—´
    
    ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š
    - åŒ»ç–—è®°å½•éœ€è¦å½“å‰æ—¥æœŸ
    - é¢„çº¦æŒ‚å·æ—¶é—´å‚è€ƒ
    - ç—…å†è®°å½•æ—¶é—´æˆ³
    - ç”¨è¯å¼€å§‹æ—¥æœŸæ ‡è®°
    
    Returns:
        str: å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸º"YYYYå¹´MMæœˆDDæ—¥"
    
    Example:
        è°ƒç”¨è¯¥å·¥å…·å°†è¿”å›ç±»ä¼¼"2024å¹´12æœˆ19æ—¥"çš„æ—¥æœŸå­—ç¬¦ä¸²
    """
    result = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    logger.info(f"get_current_date called, returning: {result}")
    return result


@mcp.tool()
def get_current_time() -> str:
    """è·å–å½“å‰ç³»ç»Ÿæ—¶é—´
    
    è¿™ä¸ªå·¥å…·ç”¨äºè·å–å½“å‰çš„ç³»ç»Ÿæ—¶é—´ï¼Œè¿”å›24å°æ—¶åˆ¶æ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸²ã€‚
    
    â° åŠŸèƒ½è¯´æ˜ï¼š
    - è·å–å®æ—¶çš„å½“å‰æ—¶é—´
    - è¿”å›æ ¼å¼ï¼šHH:MM:SSï¼ˆå¦‚ï¼š14:30:25ï¼‰
    - ä½¿ç”¨24å°æ—¶åˆ¶
    - åŸºäºç³»ç»Ÿæœ¬åœ°æ—¶é—´
    
    ğŸ¯ é€‚ç”¨åœºæ™¯ï¼š
    - åŒ»ç–—æ“ä½œæ—¶é—´è®°å½•
    - ç”¨è¯æ—¶é—´æé†’
    - æ£€æŸ¥æ—¶é—´æ ‡è®°
    - æ€¥è¯Šæ—¶é—´è®°å½•
    - æ‰‹æœ¯æ—¶é—´è®°å½•
    
    Returns:
        str: å½“å‰æ—¶é—´ï¼Œæ ¼å¼ä¸º"HH:MM:SS"
    
    Example:
        è°ƒç”¨è¯¥å·¥å…·å°†è¿”å›ç±»ä¼¼"14:30:25"çš„æ—¶é—´å­—ç¬¦ä¸²
    """
    result = datetime.now().strftime("%H:%M:%S")
    logger.info(f"get_current_time called, returning: {result}")
    return result


@mcp.tool()
def medical_qa_search(question: str) -> str:
    """ä¸“ä¸šåŒ»å­¦çŸ¥è¯†åº“æ£€ç´¢é—®ç­”å·¥å…·
    
    è¿™æ˜¯ä¸€ä¸ªåŸºäºå…ˆè¿›AIæŠ€æœ¯çš„åŒ»å­¦çŸ¥è¯†æ£€ç´¢ç³»ç»Ÿï¼Œèƒ½å¤Ÿä»ä¸“ä¸šåŒ»å­¦çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶ç”Ÿæˆå‡†ç¡®çš„åŒ»å­¦ç­”æ¡ˆã€‚
    
    ğŸ”¬ æŠ€æœ¯ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨HyDEï¼ˆå‡è®¾æ€§æ–‡æ¡£åµŒå…¥ï¼‰æŠ€æœ¯æé«˜æ£€ç´¢ç²¾åº¦
    - ç»“åˆQAé—®ç­”å¯¹å’ŒåŸå§‹åŒ»å­¦æ–‡æ¡£è¿›è¡Œæ£€ç´¢
    - ä½¿ç”¨RankGPTé‡æ’åºç®—æ³•ä¼˜åŒ–ç»“æœç›¸å…³æ€§
    - åŸºäºOpenAI GPT-4æ¨¡å‹ç”Ÿæˆä¸“ä¸šç­”æ¡ˆ
    
    ğŸ“š çŸ¥è¯†åº“å†…å®¹ï¼š
    - ç–¾ç—…è¯Šæ–­æŒ‡å—
    - æ²»ç–—æ–¹æ¡ˆå’Œç”¨è¯æŒ‡å¯¼
    - ç—‡çŠ¶åˆ†æå’Œé‰´åˆ«è¯Šæ–­
    - åŒ»å­¦æœ¯è¯­å’Œæ¦‚å¿µè§£é‡Š
    - é¢„é˜²ä¿å¥çŸ¥è¯†
    
    Args:
        question (str): åŒ»å­¦ç›¸å…³é—®é¢˜ï¼Œæ”¯æŒä¸­æ–‡è‡ªç„¶è¯­è¨€æé—®
            
            é—®é¢˜ç±»å‹ç¤ºä¾‹ï¼š
            - ç–¾ç—…ç—‡çŠ¶ï¼š"ç³–å°¿ç—…æœ‰ä»€ä¹ˆç—‡çŠ¶ï¼Ÿ"
            - æ²»ç–—æ–¹æ³•ï¼š"é«˜è¡€å‹çš„æ²»ç–—æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ"
            - è¯Šæ–­æŒ‡å—ï¼š"å¦‚ä½•è¯Šæ–­å† å¿ƒç—…ï¼Ÿ"
            - ç”¨è¯æŒ‡å¯¼ï¼š"é˜¿å¸åŒ¹æ—çš„ç”¨æ³•ç”¨é‡æ˜¯ä»€ä¹ˆï¼Ÿ"
            - é¢„é˜²ä¿å¥ï¼š"å¦‚ä½•é¢„é˜²å¿ƒè„‘è¡€ç®¡ç–¾ç—…ï¼Ÿ"
            - æœ¯è¯­è§£é‡Šï¼š"ä»€ä¹ˆæ˜¯å¿ƒæˆ¿é¢¤åŠ¨ï¼Ÿ"
            - æ£€æŸ¥é¡¹ç›®ï¼š"å¿ƒç”µå›¾èƒ½æ£€æŸ¥å‡ºä»€ä¹ˆé—®é¢˜ï¼Ÿ"
    
    Returns:
        str: åŸºäºåŒ»å­¦çŸ¥è¯†åº“æ£€ç´¢çš„è¯¦ç»†ä¸“ä¸šç­”æ¡ˆ
            - å†…å®¹å‡†ç¡®å¯é ï¼Œæ¥æºäºæƒå¨åŒ»å­¦èµ„æ–™
            - ç»“æ„åŒ–ç»„ç»‡ä¿¡æ¯ï¼Œæ˜“äºç†è§£
            - åŒ…å«ç—‡çŠ¶ã€è¯Šæ–­ã€æ²»ç–—ç­‰å…¨æ–¹ä½ä¿¡æ¯
            - ä½¿ç”¨ä¸“ä¸šåŒ»å­¦æœ¯è¯­ï¼ŒåŒæ—¶å…¼é¡¾é€šä¿—æ˜“æ‡‚
    
    âš ï¸ é‡è¦æé†’ï¼š
    - æœ¬å·¥å…·æä¾›çš„ä¿¡æ¯ä»…ä¾›åŒ»å­¦ç§‘æ™®å’Œå‚è€ƒ
    - ä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­å’Œæ²»ç–—å»ºè®®
    - å¦‚æœ‰å¥åº·é—®é¢˜ï¼Œè¯·åŠæ—¶å°±åŒ»å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
    - ç”¨è¯è¯·éµåŒ»å˜±ï¼Œä¸å¯è‡ªè¡Œè¯Šæ–­ç”¨è¯
    
    Example:
        question = "ä»‹ç»ä¸€ä¸‹é£Ÿç®¡ç™Œçš„ç—‡çŠ¶"
        è¿”å›: è¯¦ç»†çš„é£Ÿç®¡ç™Œç—‡çŠ¶æè¿°ï¼ŒåŒ…æ‹¬æ—©æœŸç—‡çŠ¶ã€è¿›å±•ç—‡çŠ¶ã€å¹¶å‘ç—‡ç­‰
    """
    if not qa_system_available:
        error_msg = "QAæ£€ç´¢ç³»ç»Ÿä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥OPENAI_API_KEYç¯å¢ƒå˜é‡æˆ–ç›¸å…³ä¾èµ–"
        logger.error(error_msg)
        return error_msg
    
    try:
        logger.info(f"medical_qa_search called with question: {question}")
        
        # ä½¿ç”¨QAæ£€ç´¢å›¾è¿›è¡Œå¤„ç†
        response = qa_graph.invoke({"question": question})
        answer = response["answer"].content
        
        logger.info(f"medical_qa_search success, answer length: {len(answer)}")
        return answer
        
    except Exception as e:
        error_msg = f"åŒ»å­¦é—®ç­”æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        logger.error(f"medical_qa_search error: {error_msg}")
        return error_msg


@mcp.tool()
def get_hospital_info(cnName: str = "", address: str = "", enName: str = "", cnShort: str = "", hospitalType: str = "", level: str = "", ownership: str = "", pageSize: int = 10) -> str:
    """å…¨å›½åŒ»é™¢ä¿¡æ¯æŸ¥è¯¢å·¥å…·
    
    è¿™æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»é™¢ä¿¡æ¯æŸ¥è¯¢ç³»ç»Ÿï¼Œè¿æ¥å…¨å›½åŒ»é™¢æ•°æ®åº“ï¼Œæä¾›è¯¦ç»†çš„åŒ»é™¢ä¿¡æ¯æŸ¥è¯¢æœåŠ¡ã€‚
    æ”¯æŒå¤šç»´åº¦æœç´¢æ¡ä»¶ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿæ‰¾åˆ°åˆé€‚çš„åŒ»ç–—æœºæ„ã€‚
    
    ğŸ¥ æŸ¥è¯¢åŠŸèƒ½ï¼š
    - æ”¯æŒç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³Šæœç´¢
    - å¤šæ¡ä»¶ç»„åˆæŸ¥è¯¢
    - å®æ—¶è·å–æœ€æ–°åŒ»é™¢ä¿¡æ¯
    - æä¾›è¯¦ç»†åŒ»é™¢èµ„æ–™
    
    ğŸ“Š è¿”å›ä¿¡æ¯åŒ…æ‹¬ï¼š
    - åŒ»é™¢åŸºæœ¬ä¿¡æ¯ï¼ˆåç§°ã€åœ°å€ã€ç”µè¯ï¼‰
    - åŒ»é™¢è§„æ¨¡ï¼ˆåºŠä½æ•°ã€å‘˜å·¥æ•°ï¼‰
    - åŒ»é™¢ç­‰çº§å’Œæ€§è´¨
    - å»ºé™¢æ—¶é—´å’Œç®€ä»‹
    - å®˜æ–¹ç½‘ç«™
    
    Args:
        cnName (str, optional): åŒ»é™¢ä¸­æ–‡åç§°
            - æ”¯æŒæ¨¡ç³Šæœç´¢ï¼Œå¦‚è¾“å…¥"äººæ°‘åŒ»é™¢"å¯æ‰¾åˆ°æ‰€æœ‰åŒ…å«æ­¤å…³é”®è¯çš„åŒ»é™¢
            - ç¤ºä¾‹ï¼š"åŒ—äº¬åå’ŒåŒ»é™¢"ã€"ä¸Šæµ·ç¬¬ä¸€äººæ°‘åŒ»é™¢"
            - ç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶åŒ»é™¢åç§°
            
        address (str, optional): åŒ»é™¢åœ°å€æˆ–æ‰€åœ¨åœ°åŒº
            - æ”¯æŒçœå¸‚åŒºå¿çº§æœç´¢
            - ç¤ºä¾‹ï¼š"åŒ—äº¬å¸‚"ã€"ä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒº"ã€"å¹¿å·"
            - å¯ç”¨äºæŸ¥æ‰¾ç‰¹å®šåœ°åŒºçš„åŒ»é™¢
            
        enName (str, optional): åŒ»é™¢è‹±æ–‡åç§°
            - ç”¨äºæŸ¥è¯¢æœ‰è‹±æ–‡åç§°çš„åŒ»é™¢
            - ç¤ºä¾‹ï¼š"Peking Union Medical College Hospital"
            - ä¸»è¦ç”¨äºæŸ¥è¯¢å›½é™…åŒ–åŒ»é™¢æˆ–çŸ¥ååŒ»é™¢
            
        cnShort (str, optional): åŒ»é™¢ä¸­æ–‡ç®€ç§°æˆ–åˆ«å
            - åŒ»é™¢çš„ç®€ç§°æˆ–å¸¸ç”¨åˆ«å
            - ç¤ºä¾‹ï¼š"åå’Œ"ã€"301åŒ»é™¢"ã€"åè¥¿"
            - æ–¹ä¾¿ä½¿ç”¨åŒ»é™¢å¸¸ç”¨ç®€ç§°æŸ¥è¯¢
            
        hospitalType (str, optional): åŒ»é™¢ç±»å‹
            - å¯é€‰å€¼ï¼š"ç»¼åˆæ€§åŒ»é™¢"ã€"ä¸“ç§‘åŒ»é™¢"ã€"ä¸­åŒ»åŒ»é™¢"ã€"å¦‡å¹¼ä¿å¥é™¢"ç­‰
            - å¸®åŠ©æŸ¥æ‰¾ç‰¹å®šç±»å‹çš„åŒ»ç–—æœºæ„
            - ç¤ºä¾‹ï¼šæŸ¥æ‰¾"ä¸“ç§‘åŒ»é™¢"å¯æ‰¾åˆ°çœ¼ç§‘åŒ»é™¢ã€å¿ƒè¡€ç®¡åŒ»é™¢ç­‰
            
        level (str, optional): åŒ»é™¢ç­‰çº§
            - å¯é€‰å€¼ï¼š"ä¸‰çº§ç”²ç­‰"ã€"ä¸‰çº§ä¹™ç­‰"ã€"äºŒçº§ç”²ç­‰"ã€"äºŒçº§ä¹™ç­‰"ã€"ä¸€çº§ç”²ç­‰"ç­‰
            - ç”¨äºæŸ¥æ‰¾ç‰¹å®šç­‰çº§çš„åŒ»é™¢
            - ç¤ºä¾‹ï¼š"ä¸‰çº§ç”²ç­‰"æŸ¥æ‰¾æœ€é«˜ç­‰çº§åŒ»é™¢
            
        ownership (str, optional): åŒ»é™¢æ€§è´¨
            - å¯é€‰å€¼ï¼š"å…¬ç«‹"ã€"ç§ç«‹"ã€"æ°‘è¥"ã€"åˆèµ„"ç­‰
            - ç”¨äºåŒºåˆ†åŒ»é™¢çš„æ‰€æœ‰åˆ¶æ€§è´¨
            - ç¤ºä¾‹ï¼š"å…¬ç«‹"æŸ¥æ‰¾å…¬ç«‹åŒ»é™¢
            
        pageSize (int, optional): æ¯é¡µæ˜¾ç¤ºçš„åŒ»é™¢æ•°é‡
            - é»˜è®¤å€¼ï¼š10
            - èŒƒå›´ï¼š1-50
            - æ§åˆ¶è¿”å›ç»“æœçš„æ•°é‡ï¼Œé¿å…ä¿¡æ¯è¿‡è½½
    
    Returns:
        str: æ ¼å¼åŒ–çš„åŒ»é™¢ä¿¡æ¯åˆ—è¡¨
            åŒ…å«ä»¥ä¸‹è¯¦ç»†ä¿¡æ¯ï¼š
            - åŒ»é™¢ä¸­æ–‡åç§°å’Œè‹±æ–‡åç§°
            - åŒ»é™¢åœ°å€å’Œè”ç³»ç”µè¯
            - åŒ»é™¢ç±»å‹ã€ç­‰çº§å’Œæ€§è´¨
            - åºŠä½æ•°å’Œå‘˜å·¥æ•°
            - å»ºé™¢æ—¶é—´å’ŒåŒ»é™¢ç®€ä»‹
            - å®˜æ–¹ç½‘ç«™
            
            å¦‚æœæœªæ‰¾åˆ°åŒ¹é…çš„åŒ»é™¢ï¼Œä¼šè¿”å›ç›¸åº”çš„æç¤ºä¿¡æ¯ã€‚
    
    ğŸ¯ ä½¿ç”¨åœºæ™¯ï¼š
    - å°±åŒ»æ¨èï¼šæ ¹æ®åœ°åŒºå’Œä¸“ç§‘æŸ¥æ‰¾åˆé€‚åŒ»é™¢
    - åŒ»é™¢å¯¹æ¯”ï¼šæ¯”è¾ƒä¸åŒåŒ»é™¢çš„è§„æ¨¡å’Œç­‰çº§
    - è½¬é™¢å‚è€ƒï¼šæŸ¥æ‰¾ä¸Šçº§åŒ»é™¢æˆ–ä¸“ç§‘åŒ»é™¢
    - åŒ»ç–—èµ„æºè°ƒç ”ï¼šäº†è§£æŸåœ°åŒºåŒ»ç–—èµ„æºåˆ†å¸ƒ
    
    ğŸ’¡ æŸ¥è¯¢æŠ€å·§ï¼š
    1. å•æ¡ä»¶æŸ¥è¯¢ï¼šåªå¡«å†™ä¸€ä¸ªå‚æ•°è¿›è¡Œå®½æ³›æœç´¢
    2. ç»„åˆæŸ¥è¯¢ï¼šç»“åˆå¤šä¸ªæ¡ä»¶ç²¾ç¡®æŸ¥æ‰¾
    3. åœ°åŒºæŸ¥è¯¢ï¼šä½¿ç”¨addresså‚æ•°æŸ¥æ‰¾æœ¬åœ°åŒ»é™¢
    4. ç­‰çº§ç­›é€‰ï¼šä½¿ç”¨levelå‚æ•°æŸ¥æ‰¾é«˜ç­‰çº§åŒ»é™¢
    
    Example:
        # æŸ¥æ‰¾åŒ—äº¬çš„ä¸‰çº§ç”²ç­‰åŒ»é™¢
        cnName="", address="åŒ—äº¬", level="ä¸‰çº§ç”²ç­‰"
        
        # æŸ¥æ‰¾åå’ŒåŒ»é™¢çš„è¯¦ç»†ä¿¡æ¯
        cnName="åå’ŒåŒ»é™¢"
        
        # æŸ¥æ‰¾ä¸Šæµ·çš„ä¸“ç§‘åŒ»é™¢
        address="ä¸Šæµ·", hospitalType="ä¸“ç§‘åŒ»é™¢"
    """
    try:
        # API URL
        url = "http://localhost:48080/admin-api/datamanagement/hospital/page"
        
        # è¯·æ±‚å‚æ•°
        params = {
            "pageSize": pageSize
        }
        
        # æ·»åŠ æ‰€æœ‰æœç´¢æ¡ä»¶åˆ°å‚æ•°ä¸­
        if cnName:
            params["cnName"] = cnName
        if address:
            params["address"] = address
        if enName:
            params["enName"] = enName
        if cnShort:
            params["cnShort"] = cnShort
        if hospitalType:
            params["hospitalType"] = hospitalType
        if level:
            params["level"] = level
        if ownership:
            params["ownership"] = ownership
        
        # è¯·æ±‚å¤´
        headers = {
            "tenant-id": "1",
            "Content-Type": "application/json"
        }
        
        logger.info(f"get_hospital_info called with cnName='{cnName}', address='{address}', enName='{enName}', cnShort='{cnShort}', hospitalType='{hospitalType}', level='{level}', ownership='{ownership}', pageSize={pageSize}")
        
        # å‘é€HTTPè¯·æ±‚
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        
        # è§£æå“åº”æ•°æ®
        data = response.json()
        
        if data.get("code") == 0:
            hospital_list = data.get("data", {}).get("list", [])
            total = data.get("data", {}).get("total", 0)
            
            if hospital_list:
                # æ ¼å¼åŒ–åŒ»é™¢ä¿¡æ¯
                search_conditions = []
                if cnName:
                    search_conditions.append(f"åŒ»é™¢åç§°: {cnName}")
                if address:
                    search_conditions.append(f"åœ°å€: {address}")
                if enName:
                    search_conditions.append(f"è‹±æ–‡åç§°: {enName}")
                if cnShort:
                    search_conditions.append(f"ä¸­æ–‡ç®€ç§°: {cnShort}")
                if hospitalType:
                    search_conditions.append(f"åŒ»é™¢ç±»å‹: {hospitalType}")
                if level:
                    search_conditions.append(f"åŒ»é™¢ç­‰çº§: {level}")
                if ownership:
                    search_conditions.append(f"åŒ»é™¢æ€§è´¨: {ownership}")
                
                result_info = f"æ‰¾åˆ° {total} å®¶åŒ»é™¢"
                if search_conditions:
                    search_info = "ã€".join(search_conditions)
                    result_info += f"ï¼ˆæœç´¢æ¡ä»¶ï¼š{search_info}ï¼‰"
                result_info += "ï¼š\n\n"
                
                for hospital in hospital_list:
                    result_info += f"åŒ»é™¢ä¸­æ–‡åç§°ï¼š{hospital.get('cnName', 'æœªçŸ¥')}\n"
                    result_info += f"åŒ»é™¢ä¸­æ–‡ç¼©å†™åç§°ï¼š{hospital.get('cnShort', 'æœªçŸ¥')}\n"
                    result_info += f"åŒ»é™¢è‹±æ–‡åç§°ï¼š{hospital.get('enName', 'æœªçŸ¥')}\n"
                    result_info += f"åŒ»é™¢ç±»å‹ï¼š{hospital.get('hospitalType', 'æœªçŸ¥')}\n"
                    result_info += f"åŒ»é™¢ç­‰çº§ï¼š{hospital.get('level', 'æœªçŸ¥')}\n"
                    result_info += f"æ‰€æœ‰åˆ¶ï¼š{hospital.get('ownership', 'æœªçŸ¥')}\n"
                    result_info += f"åœ°å€ï¼š{hospital.get('address', 'æœªçŸ¥')}\n"
                    result_info += f"ç”µè¯ï¼š{hospital.get('phone', 'æœªæä¾›')}\n"
                    result_info += f"åºŠä½æ•°ï¼š{hospital.get('bedCount', 0)}\n"
                    result_info += f"å‘˜å·¥æ•°ï¼š{hospital.get('staffCount', 0)}\n"
                    if hospital.get('establishedYear'):
                        result_info += f"å»ºé™¢æ—¶é—´ï¼š{hospital.get('establishedYear')}å¹´\n"
                    if hospital.get('introduction'):
                        intro = hospital.get('introduction', '')
                        result_info += f"åŒ»é™¢ç®€ä»‹ï¼š{intro}...\n"
                    result_info += f"ç½‘ç«™ï¼š{hospital.get('website', 'æœªæä¾›')}\n"
                    result_info += "\n" + "="*50 + "\n\n"
                
                logger.info(f"get_hospital_info success: found {total} hospitals")
                return result_info
            else:
                search_conditions = []
                if cnName:
                    search_conditions.append(f"åŒ»é™¢åç§°: {cnName}")
                if address:
                    search_conditions.append(f"åœ°å€: {address}")
                if enName:
                    search_conditions.append(f"è‹±æ–‡åç§°: {enName}")
                if cnShort:
                    search_conditions.append(f"ä¸­æ–‡ç®€ç§°: {cnShort}")
                if hospitalType:
                    search_conditions.append(f"åŒ»é™¢ç±»å‹: {hospitalType}")
                if level:
                    search_conditions.append(f"åŒ»é™¢ç­‰çº§: {level}")
                if ownership:
                    search_conditions.append(f"åŒ»é™¢æ€§è´¨: {ownership}")
                search_text = "ã€".join(search_conditions) if search_conditions else "æ— ç‰¹å®šæ¡ä»¶"
                
                result = f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åŒ»é™¢ï¼ˆæœç´¢æ¡ä»¶ï¼š{search_text}ï¼‰"
                logger.info(f"get_hospital_info: no hospitals found")
                return result
        else:
            error_msg = f"APIè¿”å›é”™è¯¯ï¼š{data.get('msg', 'æœªçŸ¥é”™è¯¯')}"
            logger.error(f"get_hospital_info API error: {error_msg}")
            return error_msg
            
    except requests.exceptions.RequestException as e:
        error_msg = f"ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼š{str(e)}"
        logger.error(f"get_hospital_info network error: {error_msg}")
        return error_msg
    except json.JSONDecodeError as e:
        error_msg = f"JSONè§£æå¤±è´¥ï¼š{str(e)}"
        logger.error(f"get_hospital_info JSON error: {error_msg}")
        return error_msg
    except Exception as e:
        error_msg = f"è·å–åŒ»é™¢ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        logger.error(f"get_hospital_info unexpected error: {error_msg}")
        return error_msg

# å¯åŠ¨MCPæœåŠ¡å™¨
if __name__ == "__main__":

    # å¯åŠ¨æœåŠ¡å™¨
    mcp.run(
        transport="sse",
        host="127.0.0.1",
        port=8001
    )
