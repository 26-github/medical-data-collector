from langchain_mcp_adapters.client import MultiServerMCPClient
from fastapi import FastAPI
from contextlib import asynccontextmanager
from langchain_mcp_adapters.tools import load_mcp_tools
import subprocess
import sys
import atexit
import asyncio
import httpx
from dotenv import load_dotenv
from typing import Any, Optional, Dict

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

from method import *
from api import *
from medical_attachment_processor import medical_processor
import re
import json
import hashlib
import pickle
import time
from pathlib import Path
from datetime import datetime, timedelta

# å¯¼å…¥ä¸“ç”¨ç¼“å­˜
from method import _response_cache


# åˆå§‹åŒ–llmï¼ˆæ·»åŠ è¶…æ—¶å’Œé‡è¯•é…ç½®ï¼‰
# æ³¨æ„ï¼šERNIEæ¨¡å‹å¯èƒ½ä¸æ”¯æŒåŸç”Ÿfunction callingï¼Œè€ƒè™‘ä½¿ç”¨æ”¯æŒçš„æ¨¡å‹


# å¦‚æœéœ€è¦function callingï¼Œè€ƒè™‘ä½¿ç”¨æ”¯æŒçš„æ¨¡å‹ï¼š
# from langchain_openai import ChatOpenAI
# llm_for_data = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)
llm_for_data = ChatOpenAI(
    model="qwen-max",
    temperature=0.1,
    request_timeout=60,
    max_retries=3,
    openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
    openai_api_key=os.getenv("DASHSCOPE_API_KEY"),
)
# åˆ é™¤å¤šä½™çš„LLMå®ä¾‹ï¼Œåªä¿ç•™ä¸»è¦çš„æ•°æ®æ”¶é›†LLM
# llm_for_generating_preset å’Œ llm_for_translate å·²åˆ é™¤ä»¥æå‡æ€§èƒ½

# æ‹¿åˆ°æç¤ºè¯æ¨¡æ¿
prompt_collecting = get_prompt_for_collecting_data()
prompt_prefabricated_words = get_prompt_for_generating_preset()

# ç®€åŒ–çš„ç¼“å­˜ç®¡ç†å™¨
class SimpleCache:
    def __init__(self):
        self.cache_dir = Path("simple_cache")
        self.cache_dir.mkdir(exist_ok=True)
        self.memory_cache = {}
        self.stats = {'hits': 0, 'misses': 0}
        
    def _generate_key(self, cache_type: str, identifier: str, extra: str = "") -> str:
        content = f"{cache_type}_{identifier}_{extra}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    async def get(self, cache_type: str, identifier: str, extra: str = "") -> Any:
        key = self._generate_key(cache_type, identifier, extra)
        
        # æ£€æŸ¥å†…å­˜ç¼“å­˜
        if key in self.memory_cache:
            entry = self.memory_cache[key]
            if time.time() - entry['created'] < entry['ttl']:
                self.stats['hits'] += 1
                logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_type}")
                return entry['data']
            else:
                del self.memory_cache[key]
        
        # æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cache_file = self.cache_dir / f"{key}.pkl"
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    entry = pickle.load(f)
                if time.time() - entry['created'] < entry['ttl']:
                    self.memory_cache[key] = entry
                    self.stats['hits'] += 1
                    logger.debug(f"ç£ç›˜ç¼“å­˜å‘½ä¸­: {cache_type}")
                    return entry['data']
                else:
                    cache_file.unlink()
            except:
                if cache_file.exists():
                    cache_file.unlink()
        
        self.stats['misses'] += 1
        return None
    
    async def set(self, cache_type: str, identifier: str, data: Any, ttl: int = 3600, extra: str = ""):
        key = self._generate_key(cache_type, identifier, extra)
        entry = {
            'data': data,
            'created': time.time(),
            'ttl': ttl
        }
        
        # ä¿å­˜åˆ°å†…å­˜
        self.memory_cache[key] = entry
        
        # ä¿å­˜åˆ°ç£ç›˜
        try:
            cache_file = self.cache_dir / f"{key}.pkl"
            with open(cache_file, 'wb') as f:
                pickle.dump(entry, f)
        except Exception as e:
            logger.warning(f"ä¿å­˜ç¼“å­˜åˆ°ç£ç›˜å¤±è´¥: {e}")
    
    def get_stats(self):
        total = self.stats['hits'] + self.stats['misses']
        hit_rate = (self.stats['hits'] / total * 100) if total > 0 else 0
        return {
            'hits': self.stats['hits'],
            'misses': self.stats['misses'],
            'hit_rate': round(hit_rate, 2),
            'memory_entries': len(self.memory_cache)
        }

# å…¨å±€ç¼“å­˜å®ä¾‹
simple_cache = SimpleCache()



tools = None
mcp_server = None
server_process = None

def extract_tool_calls_from_text(content, available_tools):
    """
    ä»AIæ–‡æœ¬å›å¤ä¸­è§£æå·¥å…·è°ƒç”¨æŒ‡ä»¤
    é€‚ç”¨äºä¸æ”¯æŒåŸç”Ÿfunction callingçš„æ¨¡å‹
    """
    tool_calls = []
    
    # å®šä¹‰å¯èƒ½çš„å·¥å…·è°ƒç”¨æ¨¡å¼
    patterns = [
        r'è°ƒç”¨å·¥å…·ï¼š(\w+)\s*(?:å‚æ•°ï¼š(.+?))?',
        r'ä½¿ç”¨(\w+)å·¥å…·\s*(?:å‚æ•°ï¼š(.+?))?',
        r'æ‰§è¡Œ(\w+)\s*(?:å‚æ•°ï¼š(.+?))?',
        r'éœ€è¦è°ƒç”¨(\w+)\s*(?:å‚æ•°ï¼š(.+?))?',
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«åŒ»ç–—ç›¸å…³å…³é”®è¯ï¼Œå¦‚æœæ˜¯åˆ™å¼ºåˆ¶è°ƒç”¨medical_qa_search
    medical_keywords = ['åŒ»ç–—', 'ç—…æƒ…', 'è¯Šæ–­', 'æ²»ç–—', 'ç—‡çŠ¶', 'å¿ƒè„', 'è¶…å£°', 'æŠ¥å‘Š', 'æ£€æŸ¥']
    if any(keyword in content for keyword in medical_keywords):
        # åˆ›å»ºåŒ»ç–—æŸ¥è¯¢å·¥å…·è°ƒç”¨
        tool_call = {
            "id": f"medical_qa_search_{len(tool_calls)}",
            "function": {
                "name": "medical_qa_search",
                "arguments": json.dumps({
                    "question": content[:200]  # ä½¿ç”¨å‰200å­—ç¬¦ä½œä¸ºé—®é¢˜
                }, ensure_ascii=False)
            }
        }
        tool_calls.append(tool_call)
        logger.info("æ£€æµ‹åˆ°åŒ»ç–—ç›¸å…³å†…å®¹ï¼Œè‡ªåŠ¨è§¦å‘medical_qa_searchå·¥å…·è°ƒç”¨")
    
    # å°è¯•åŒ¹é…æ˜ç¡®çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤
    for pattern in patterns:
        matches = re.findall(pattern, content)
        for match in matches:
            tool_name = match[0] if isinstance(match, tuple) else match
            arguments = match[1] if isinstance(match, tuple) and len(match) > 1 else "{}"
            
            # éªŒè¯å·¥å…·æ˜¯å¦å­˜åœ¨
            tool_names = [tool.name for tool in available_tools] if available_tools else []
            if tool_name in tool_names:
                try:
                    args_dict = json.loads(arguments) if arguments else {}
                except:
                    args_dict = {"query": arguments} if arguments else {}
                
                tool_call = {
                    "id": f"{tool_name}_{len(tool_calls)}",
                    "function": {
                        "name": tool_name,
                        "arguments": json.dumps(args_dict, ensure_ascii=False)
                    }
                }
                tool_calls.append(tool_call)
    
    return tool_calls

async def check_mcp_server_health():
    """æ£€æŸ¥MCPæœåŠ¡å™¨æ˜¯å¦å¥åº·è¿è¡Œ"""
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # FastMCPä½¿ç”¨SSEç«¯ç‚¹ï¼Œç›´æ¥æµ‹è¯•SSEè¿æ¥
            async with httpx.AsyncClient(timeout=10.0) as client:  # å¢åŠ è¶…æ—¶æ—¶é—´
                response = await client.get("http://127.0.0.1:18002/sse/")
                # å¯¹äºSSEç«¯ç‚¹ï¼Œ200æˆ–å…¶ä»–é4xxé”™è¯¯éƒ½è¡¨ç¤ºæœåŠ¡å™¨åœ¨è¿è¡Œ
                if response.status_code < 400 or response.status_code == 502:
                    return True
        except Exception as e:
            logger.warning(f"MCPå¥åº·æ£€æŸ¥å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
            # å¦‚æœSSEå¤±è´¥ï¼Œå°è¯•æ ¹è·¯å¾„æµ‹è¯•
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get("http://127.0.0.1:18002/")
                    if response.status_code < 500:  # ä»»ä½•éæœåŠ¡å™¨é”™è¯¯éƒ½è¡¨ç¤ºæœåŠ¡å™¨åœ¨è¿è¡Œ
                        return True
            except Exception as e2:
                logger.warning(f"MCPæ ¹è·¯å¾„æ£€æŸ¥ä¹Ÿå¤±è´¥: {e2}")
                
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
    
    return False

async def tool_list():
    """åˆå§‹åŒ–MCPå®¢æˆ·ç«¯å’Œå·¥å…·"""
    global tools, mcp_server
    
    # æ·»åŠ è¿æ¥é‡è¯•æœºåˆ¶
    max_retries = 10
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            # ä½¿ç”¨127.0.0.1è€Œä¸æ˜¯localhostï¼Œé¿å…DNSè§£æé—®é¢˜
            mcp_server = MultiServerMCPClient({
                "medical_tools": {
                    "url": "http://127.0.0.1:18002/sse/", # æ³¨æ„æœ«å°¾çš„æ–œæ 
                    "transport": "sse",
                }
            })

            # è·å–MCPå·¥å…·ï¼Œæ·»åŠ è¶…æ—¶æ§åˆ¶
            async with mcp_server.session("medical_tools") as session:
                # ä½¿ç”¨asyncio.wait_foræ·»åŠ è¶…æ—¶æ§åˆ¶
                tools = await asyncio.wait_for(
                    load_mcp_tools(session),
                    timeout=30.0  # 30ç§’è¶…æ—¶
                )
                logger.info(f"å·²åŠ è½½ {len(tools)} ä¸ªå·¥å…·")
                return  # æˆåŠŸè¿æ¥ï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                
        except asyncio.TimeoutError:
            logger.warning(f"MCPå·¥å…·åŠ è½½è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{max_retries}")
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„è¿æ¥
            try:
                if mcp_server:
                    await mcp_server.close()
            except:
                pass
            mcp_server = None
            
        except Exception as e:
            logger.warning(f"MCPè¿æ¥å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„è¿æ¥
            try:
                if mcp_server:
                    await mcp_server.close()
            except:
                pass
            mcp_server = None
            
        # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
        if attempt < max_retries - 1:
            logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
            await asyncio.sleep(retry_delay)
            retry_delay = min(retry_delay * 1.5, 10)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§10ç§’
        else:
            logger.error("æ‰€æœ‰MCPè¿æ¥å°è¯•éƒ½å¤±è´¥äº†ï¼Œå°†åœ¨æ²¡æœ‰å·¥å…·çš„æƒ…å†µä¸‹ç»§ç»­è¿è¡Œ")
            tools = []  # è®¾ç½®ä¸ºç©ºåˆ—è¡¨ï¼Œé¿å…åç»­é”™è¯¯



def start_mcp_server():
    """å¯åŠ¨MCPæœåŠ¡å™¨"""
    global server_process
    try:
        # è·å–server.pyçš„ç»å¯¹è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        server_path = os.path.join(current_dir, "..", "mcp_server", "server.py")
        server_path = os.path.normpath(server_path)

        logger.info(f"æ­£åœ¨å¯åŠ¨MCPæœåŠ¡å™¨: {server_path}")

        # å¯åŠ¨server.pyè¿›ç¨‹
        server_process = subprocess.Popen([
            sys.executable, server_path
        ], cwd=os.path.dirname(server_path), 
        stdout=subprocess.PIPE, 
        stderr=subprocess.PIPE)

        logger.info(f"MCPæœåŠ¡å™¨å·²å¯åŠ¨ï¼Œè¿›ç¨‹ID: {server_process.pid}")

        # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œè®©æœåŠ¡å™¨å®Œå…¨å¯åŠ¨
        time.sleep(8)

        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
        if server_process.poll() is None:
            logger.info("MCPæœåŠ¡å™¨è¿›ç¨‹è¿è¡Œæ­£å¸¸")
            return True
        else:
            # è¿›ç¨‹å·²ç»é€€å‡ºï¼Œè·å–é”™è¯¯ä¿¡æ¯
            stdout, stderr = server_process.communicate()
            logger.error(f"MCPæœåŠ¡å™¨å¯åŠ¨å¤±è´¥ï¼Œé€€å‡ºç : {server_process.returncode}")
            if stdout:
                logger.error(f"æ ‡å‡†è¾“å‡º: {stdout.decode()}")
            if stderr:
                logger.error(f"æ ‡å‡†é”™è¯¯: {stderr.decode()}")
            return False

    except Exception as e:
        logger.error(f"å¯åŠ¨MCPæœåŠ¡å™¨å¤±è´¥: {e}")
        return False

def stop_mcp_server():
    """åœæ­¢MCPæœåŠ¡å™¨"""
    global server_process
    if server_process:
        try:
            logger.info("æ­£åœ¨å…³é—­MCPæœåŠ¡å™¨...")
            server_process.terminate()

            # ç­‰å¾…è¿›ç¨‹æ­£å¸¸ç»“æŸ
            try:
                server_process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                # å¦‚æœ5ç§’åè¿˜æ²¡ç»“æŸï¼Œå¼ºåˆ¶æ€æ­»è¿›ç¨‹
                server_process.kill()
                server_process.wait()

            logger.info("MCPæœåŠ¡å™¨å·²å…³é—­")
            server_process = None
        except Exception as e:
            logger.error(f"å…³é—­MCPæœåŠ¡å™¨æ—¶å‡ºé”™: {e}")

@asynccontextmanager
async def lifespan(app):
    """
    åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨ï¼Œåœ¨å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹å’Œå·¥å…·
    """
    logger.info("åº”ç”¨å¯åŠ¨ä¸­...")
    
    # æµ‹è¯•S3è¿æ¥
    logger.info("æµ‹è¯•S3è¿æ¥...")
    s3_connected = await medical_processor.test_s3_connection()
    if s3_connected:
        logger.info("âœ… S3è¿æ¥æ­£å¸¸")
    else:
        logger.warning("âš ï¸ S3è¿æ¥å¤±è´¥ï¼ŒåŒ»ç–—é™„ä»¶åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    
    # å¯åŠ¨MCPæœåŠ¡å™¨
    if not start_mcp_server():
        logger.error("MCPæœåŠ¡å™¨å¯åŠ¨å¤±è´¥ï¼Œä½†ç»§ç»­å¯åŠ¨å®¢æˆ·ç«¯...")
    else:
        # ç­‰å¾…å¹¶æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶æ€
        for i in range(5):
            await asyncio.sleep(2)
            if await check_mcp_server_health():
                logger.info("âœ… MCPæœåŠ¡å™¨å¥åº·æ£€æŸ¥é€šè¿‡")
                break
            logger.info(f"ç­‰å¾…MCPæœåŠ¡å™¨å°±ç»ª... ({i+1}/5)")
        else:
            logger.warning("âš ï¸ MCPæœåŠ¡å™¨å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œä½†ç»§ç»­å¯åŠ¨")
    
    # æ³¨å†Œé€€å‡ºæ—¶å…³é—­æœåŠ¡å™¨çš„å‡½æ•°
    atexit.register(stop_mcp_server)
    
    # åˆå§‹åŒ–MCPå®¢æˆ·ç«¯å’Œå·¥å…·
    await tool_list()
    
    if tools and len(tools) > 0:
        logger.info(f"âœ… Agentåˆå§‹åŒ–å®Œæˆï¼ŒæœåŠ¡å™¨å‡†å¤‡å°±ç»ªã€‚å·²åŠ è½½ {len(tools)} ä¸ªå·¥å…·")
    else:
        logger.warning("âš ï¸ Agentåˆå§‹åŒ–å®Œæˆï¼Œä½†æ²¡æœ‰å¯ç”¨çš„å·¥å…·ã€‚å®¢æˆ·ç«¯å°†åœ¨åŸºç¡€æ¨¡å¼ä¸‹è¿è¡Œ")
    
    yield
    
    # åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†å·¥ä½œ
    logger.info("åº”ç”¨æ­£åœ¨å…³é—­...")
    stop_mcp_server()

app = FastAPI(lifespan=lifespan)

#å»ºç«‹ä¸€ä¸ªç©ºå­—å…¸å­˜å‚¨æ•°æ®äºå†…å­˜ä¸­
database = {}

@app.post("/chat", response_model=ChatResponse)    #postè¯·æ±‚ï¼Œæ¥æ”¶ç”¨æˆ·æ¶ˆæ¯å’ŒIPï¼Œè¿”å›AIå›å¤å’Œç”¨æˆ·æ•°æ®
async def chat_with_ai(request: ChatRequest):
    # è·å–ç”¨æˆ·IPå’Œæ¶ˆæ¯
    user_ip = request.user_ip
    new_user_message = request.message
    user_data=request.user_data
    medical_file = request.file  # æ–°å¢ï¼šè·å–åŒ»ç–—é™„ä»¶æ–‡ä»¶å

    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°ç”¨æˆ·
    user_exists = check_user(user_ip, database)
    
    # è·å–ç”¨æˆ·æ•°æ®å­—å…¸
    if user_exists:
        # ç”¨æˆ·å­˜åœ¨ï¼Œä»æ•°æ®åº“è·å–ç°æœ‰æ•°æ®
        user_data_dict = database[user_ip]["data"]
    else:
        # æ–°ç”¨æˆ·ï¼Œä½¿ç”¨è¯·æ±‚ä¸­çš„ç”¨æˆ·æ•°æ®
        user_data_dict = user_data

    #å¦‚æœç”¨æˆ·å¯¹è¯è¶…è¿‡äºŒåæ¬¡ï¼Œå›å¤è¯·æ‰¾äººå·¥å®¢æœå¹¶å‘é€æ•°æ®åˆ°APIï¼ˆå¢å¼ºå¤šè¯­è¨€æ”¯æŒï¼‰
    if len(database[user_ip]["record"]) > 80:
        language = user_data_dict.get("language", "zh")
        # æ‰©å±•çš„å¤šè¯­è¨€æ¶ˆæ¯ï¼Œæ”¯æŒæ›´å¤šå°è¯­ç§
        service_messages = {
            "zh": "å¯¹è¯æ¬¡æ•°è¿‡å¤šï¼Œè¯·å¯»æ‰¾äººå·¥å®¢æœã€‚",
            "English": "Too many conversations, please contact human customer service.",
            "ja": "ä¼šè©±å›æ•°ãŒå¤šã™ãã¾ã™ã€‚äººé–“ã®ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚",
            "ko": "ëŒ€í™” íšŸìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì¸ê°„ ê³ ê° ì„œë¹„ìŠ¤ì— ë¬¸ì˜í•˜ì‹­ì‹œì˜¤.",
            "ar": "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª ÙƒØ«ÙŠØ± Ø¬Ø¯Ø§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø¨Ø´Ø±ÙŠØ©.",
            "th": "à¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²à¸¡à¸²à¸à¹€à¸à¸´à¸™à¹„à¸› à¸à¸£à¸¸à¸“à¸²à¸•à¸´à¸”à¸•à¹ˆà¸­à¸à¹ˆà¸²à¸¢à¸šà¸£à¸´à¸à¸²à¸£à¸¥à¸¹à¸à¸„à¹‰à¸²à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¸¡à¸™à¸¸à¸©à¸¢à¹Œ",
            "vi": "QuÃ¡ nhiá»u cuá»™c trÃ² chuyá»‡n, vui lÃ²ng liÃªn há»‡ dá»‹ch vá»¥ khÃ¡ch hÃ ng con ngÆ°á»i.",
            "hi": "à¤¬à¤¹à¥à¤¤ à¤…à¤§à¤¿à¤• à¤¬à¤¾à¤¤à¤šà¥€à¤¤, à¤•à¥ƒà¤ªà¤¯à¤¾ à¤®à¤¾à¤¨à¤µ à¤—à¥à¤°à¤¾à¤¹à¤• à¤¸à¥‡à¤µà¤¾ à¤¸à¥‡ à¤¸à¤‚à¤ªà¤°à¥à¤• à¤•à¤°à¥‡à¤‚à¥¤",
            "bn": "à¦…à¦¨à§‡à¦• à¦¬à§‡à¦¶à¦¿ à¦•à¦¥à§‹à¦ªà¦•à¦¥à¦¨, à¦¦à¦¯à¦¼à¦¾ à¦•à¦°à§‡ à¦®à¦¾à¦¨à¦¬ à¦—à§à¦°à¦¾à¦¹à¦• à¦¸à§‡à¦¬à¦¾à¦° à¦¸à¦¾à¦¥à§‡ à¦¯à§‹à¦—à¦¾à¦¯à§‹à¦— à¦•à¦°à§à¦¨à¥¤",
            "ta": "à®…à®¤à®¿à®• à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à¯à®•à®³à¯, à®®à®©à®¿à®¤ à®µà®¾à®Ÿà®¿à®•à¯à®•à¯ˆà®¯à®¾à®³à®°à¯ à®šà¯‡à®µà¯ˆà®¯à¯ˆà®¤à¯ à®¤à¯Šà®Ÿà®°à¯à®ªà¯ à®•à¯Šà®³à¯à®³à®µà¯à®®à¯.",
            "te": "à°šà°¾à°²à°¾ à°à°•à±à°•à±à°µ à°¸à°‚à°­à°¾à°·à°£à°²à±, à°¦à°¯à°šà±‡à°¸à°¿ à°®à°¾à°¨à°µ à°•à°¸à±à°Ÿà°®à°°à± à°¸à±‡à°µà°¨à± à°¸à°‚à°ªà±à°°à°¦à°¿à°‚à°šà°‚à°¡à°¿.",
            "ml": "à´µà´³à´°àµ†à´¯à´§à´¿à´•à´‚ à´¸à´‚à´­à´¾à´·à´£à´™àµà´™àµ¾, à´¦à´¯à´µà´¾à´¯à´¿ à´®à´¨àµà´·àµà´¯ à´‰à´ªà´­àµ‹à´•àµà´¤àµƒ à´¸àµ‡à´µà´¨à´¤àµà´¤àµ† à´¬à´¨àµà´§à´ªàµà´ªàµ†à´Ÿàµà´•.",
            "kn": "à²¹à³†à²šà³à²šà³ à²¸à²‚à²­à²¾à²·à²£à³†à²—à²³à³, à²¦à²¯à²µà²¿à²Ÿà³à²Ÿà³ à²®à²¾à²¨à²µ à²—à³à²°à²¾à²¹à²• à²¸à³‡à²µà³†à²¯à²¨à³à²¨à³ à²¸à²‚à²ªà²°à³à²•à²¿à²¸à²¿.",
            "gu": "àª˜àª£à«€ àª¬àª§à«€ àªµàª¾àª¤àªšà«€àª¤, àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àª®àª¾àª¨àªµ àª—à«àª°àª¾àª¹àª• àª¸à«‡àªµàª¾àª¨à«‹ àª¸àª‚àªªàª°à«àª• àª•àª°à«‹.",
            "pa": "à¨¬à¨¹à©à¨¤ à¨¸à¨¾à¨°à©€à¨†à¨‚ à¨—à©±à¨²à¨¬à¨¾à¨¤, à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨®à¨¨à©à©±à¨–à©€ à¨—à¨¾à¨¹à¨• à¨¸à©‡à¨µà¨¾ à¨¨à¨¾à¨² à¨¸à©°à¨ªà¨°à¨• à¨•à¨°à©‹à¥¤",
            "ur": "Ø¨ÛØª Ø²ÛŒØ§Ø¯Û Ú¯ÙØªÚ¯ÙˆØŒ Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø§Ù†Ø³Ø§Ù†ÛŒ Ú©Ø³Ù¹Ù…Ø± Ø³Ø±ÙˆØ³ Ø³Û’ Ø±Ø§Ø¨Ø·Û Ú©Ø±ÛŒÚºÛ”",
            "fa": "Ù…Ú©Ø§Ù„Ù…Ø§Øª Ø²ÛŒØ§Ø¯ÛŒØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ø®Ø¯Ù…Ø§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ù†Ø³Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.",
            "ru": "Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ², Ğ¿Ğ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚ĞµÑÑŒ Ğº Ñ‡ĞµĞ»Ğ¾Ğ²ĞµÑ‡ĞµÑĞºĞ¾Ğ¹ ÑĞ»ÑƒĞ¶Ğ±Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸.",
            "es": "Demasiadas conversaciones, por favor contacte al servicio al cliente humano.",
            "fr": "Trop de conversations, veuillez contacter le service client humain.",
            "de": "Zu viele GesprÃ¤che, bitte wenden Sie sich an den menschlichen Kundendienst.",
            "my": "á€…á€€á€¬á€¸á€•á€¼á€±á€¬á€™á€¾á€¯á€™á€»á€¬á€¸á€…á€½á€¬áŠ á€œá€°á€á€¬á€¸á€–á€±á€¬á€€á€ºá€á€Šá€ºá€á€”á€ºá€†á€±á€¬á€„á€ºá€™á€¾á€¯á€€á€­á€¯ á€†á€€á€ºá€á€½á€šá€ºá€•á€«á‹",
            "km": "á€á¶ášáŸá“áŸ’á‘á“á¶á…áŸ’ášá¾á“á–áŸá€ áŸá¼á˜á‘á¶á€áŸ‹á‘á„áŸáŸáœá¶á€á˜áŸ’á˜á¢áá·áá·á‡á“á˜á“á»áŸáŸ’áŸáŸ”",
            "lo": "àºàº²àº™àºªàº»àº™àº—àº°àº™àº²àº«àº¼àº²àºà»€àºàºµàº™à»„àº›, àºàº°àº¥àº¸àº™àº²àº•àº´àº”àº•à»à»ˆàºšà»àº¥àº´àºàº²àº™àº¥àº¹àºàº„à»‰àº²àº¡àº°àº™àº¸àº”.",
            "he": "×™×•×ª×¨ ××“×™ ×©×™×—×•×ª, ×× × ×¤× ×” ×œ×©×™×¨×•×ª ×œ×§×•×—×•×ª ×× ×•×©×™.",
            "ka": "áƒ«áƒáƒšáƒ˜áƒáƒœ áƒ‘áƒ”áƒ•áƒ áƒ˜ áƒ¡áƒáƒ£áƒ‘áƒáƒ áƒ˜, áƒ’áƒ—áƒ®áƒáƒ•áƒ— áƒ“áƒáƒ£áƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ“áƒ”áƒ— áƒáƒ“áƒáƒ›áƒ˜áƒáƒœáƒ£áƒ  áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒ”áƒšáƒ—áƒ áƒ¡áƒ”áƒ áƒ•áƒ˜áƒ¡áƒ¡.",
            "hy": "Õ‡Õ¡Õ¿ Õ·Õ¡Õ¿ Õ¦Ö€Õ¸Ö‚ÕµÖÕ¶Õ¥Ö€, Õ­Õ¶Õ¤Ö€Õ¸Ö‚Õ´ Õ¥Õ¶Ö„ Õ¯Õ¡ÕºÕ¾Õ¥Õ¬ Õ´Õ¡Ö€Õ¤Õ¯Õ¡ÕµÕ«Õ¶ Õ°Õ¡Õ³Õ¡Õ­Õ¸Ö€Õ¤Õ¶Õ¥Ö€Õ« Õ®Õ¡Õ¼Õ¡ÕµÕ¸Ö‚Õ©ÕµÕ¡Õ¶ Õ°Õ¥Õ¿:",
            "am": "á‰ áŒ£áˆ á‰¥á‹™ áŠ•áŒáŒáˆ®á‰½á£ áŠ¥á‰£áŠ­á‹ á‹¨áˆ°á‹ á‹°áŠ•á‰ áŠ› áŠ áŒˆáˆáŒáˆá‰µáŠ• á‹«áŠáŒ‹áŒáˆ©á¢"
        }
        
        return ChatResponse(
            user_ip=user_ip,
            ai_reply=service_messages.get(language, service_messages["zh"]),
        )

    # å¦‚æœç”¨æˆ·æ•°æ®ä¸ºç©ºï¼Œåˆ›å»ºæ–°çš„æ•°æ®å¯¹è±¡
    if not user_data_dict:
        user_data = data()
    else:
        user_data = data.model_validate(user_data_dict)

    # å¤„ç†S3åŒ»ç–—é™„ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
    medical_attachment_info = None
    if medical_file:
        # é¦–å…ˆæ£€æŸ¥ç”¨æˆ·æ•°æ®ä¸­æ˜¯å¦å·²æœ‰åŒä¸€æ–‡ä»¶çš„åŒ»ç–—é™„ä»¶åˆ†æç»“æœ
        if (user_data.medicalAttachmentFilename == medical_file and 
            user_data.medicalAttachmentAnalysis != "0" and
            user_data.medicalAttachmentAnalysis != ""):
            # ä½¿ç”¨å·²ä¿å­˜çš„åŒ»ç–—é™„ä»¶åˆ†æç»“æœ
            logger.info(f"ğŸ¯ ç›´æ¥ä½¿ç”¨ç”¨æˆ·æ•°æ®ä¸­çš„åŒ»ç–—é™„ä»¶åˆ†æ: {medical_file}")
            medical_attachment_info = {
                "status": "success_from_user_data",
                "extracted_content": user_data.medicalAttachmentAnalysis,
                "original_filename": medical_file,
                "file_type": "s3_medical_attachment"
            }
            # æ›´æ–°æ‘˜è¦
            attachment_summary = medical_processor.get_attachment_summary(medical_attachment_info)
            user_data.medicalAttachments = attachment_summary
        else:
            # éœ€è¦é‡æ–°å¤„ç†åŒ»ç–—é™„ä»¶
            try:
                logger.info(f"å¼€å§‹å¤„ç†S3åŒ»ç–—é™„ä»¶: {medical_file}")
                # ä»S3ä¸‹è½½å¹¶å¤„ç†åŒ»ç–—é™„ä»¶
                medical_attachment_info = await medical_processor.process_medical_attachment_from_s3(
                    user_ip=user_ip, 
                    filename=medical_file
                )
                
                if medical_attachment_info["status"] in ["success", "success_from_cache"]:
                    # å°†åŒ»ç–—é™„ä»¶ä¿¡æ¯æ›´æ–°åˆ°ç”¨æˆ·æ•°æ®ä¸­
                    attachment_summary = medical_processor.get_attachment_summary(medical_attachment_info)
                    user_data.medicalAttachments = attachment_summary
                    # ä¿å­˜å®Œæ•´çš„åˆ†æç»“æœå’Œæ–‡ä»¶å
                    user_data.medicalAttachmentAnalysis = medical_attachment_info["extracted_content"]
                    user_data.medicalAttachmentFilename = medical_file
                    
                    # è®°å½•å¤„ç†æ–¹å¼
                    if medical_attachment_info["status"] == "success_from_cache":
                        logger.info(f"âš¡ åŒ»ç–—é™„ä»¶ä½¿ç”¨ç¼“å­˜ç»“æœ: {medical_file}")
                    else:
                        logger.info(f"ğŸ’¾ åŒ»ç–—é™„ä»¶å¤„ç†æˆåŠŸå¹¶å·²ç¼“å­˜: {medical_file}")
                else:
                    logger.error(f"åŒ»ç–—é™„ä»¶å¤„ç†å¤±è´¥: {medical_attachment_info.get('extracted_content', 'Unknown error')}")
                    
            except Exception as e:
                logger.error(f"å¤„ç†S3åŒ»ç–—é™„ä»¶æ—¶å‡ºé”™: {e}")
                user_data.medicalAttachments = f"åŒ»ç–—é™„ä»¶å¤„ç†å¤±è´¥: {str(e)}"
    elif (user_data.medicalAttachmentFilename != "0" and 
          user_data.medicalAttachmentAnalysis != "0" and
          user_data.medicalAttachmentAnalysis != ""):
        # æ²¡æœ‰æ–°çš„åŒ»ç–—æ–‡ä»¶ï¼Œä½†ç”¨æˆ·æ•°æ®ä¸­æœ‰ä¹‹å‰çš„åŒ»ç–—é™„ä»¶ä¿¡æ¯ï¼Œç»§ç»­ä½¿ç”¨
        logger.info(f"ğŸ”„ ç»§ç»­ä½¿ç”¨ä¹‹å‰çš„åŒ»ç–—é™„ä»¶åˆ†æ: {user_data.medicalAttachmentFilename}")
        medical_attachment_info = {
            "status": "success_from_previous_data",
            "extracted_content": user_data.medicalAttachmentAnalysis,
            "original_filename": user_data.medicalAttachmentFilename,
            "file_type": "s3_medical_attachment"
        }
        # æ›´æ–°æ‘˜è¦
        attachment_summary = medical_processor.get_attachment_summary(medical_attachment_info)
        user_data.medicalAttachments = attachment_summary

    # åœ¨æ·»åŠ æ–°ç”¨æˆ·æ¶ˆæ¯å‰ï¼Œæ¸…ç†ä¹‹å‰çš„å·¥å…·æ¶ˆæ¯ä»¥é˜²æ­¢æç¤ºè¯è¿‡é•¿
    cleanup_database_record(database, user_ip)
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°è®°å½•ä¸­
    user_message = HumanMessage(content=new_user_message)
    database[user_ip]["record"].append(user_message)

    # æ­£ç¡®ç»‘å®šå·¥å…·åˆ°LLM
    if tools and len(tools) > 0:
        llm_with_tools = llm_for_data.bind_tools(tools)
        logger.info(f"å·¥å…·ç»‘å®šå®Œæˆï¼Œå¯ç”¨å·¥å…·æ•°é‡: {len(tools)}")
        tool_names = [tool.name for tool in tools]
        logger.info(f"å¯ç”¨å·¥å…·åˆ—è¡¨: {tool_names}")
    else:
        llm_with_tools = llm_for_data
        logger.warning("æ²¡æœ‰å¯ç”¨çš„å·¥å…·ï¼Œä½¿ç”¨ä¸å¸¦å·¥å…·çš„LLM")
    
    # åˆ›å»ºå¤„ç†é“¾
    chain = prompt_collecting | llm_with_tools
    
    # å‡†å¤‡è¾“å…¥æ•°æ®ï¼Œä½¿ç”¨å½“å‰çš„ç”¨æˆ·æ•°æ®ï¼ˆåŒ…å«å¯èƒ½çš„åŒ»ç–—é™„ä»¶ä¿¡æ¯ï¼‰
    input_data = {
        "query": new_user_message, 
        "data": user_data.model_dump(),
        "record": database[user_ip]["record"],
        "language": user_data.language
    }
    
    # å¦‚æœæœ‰åŒ»ç–—é™„ä»¶ä¿¡æ¯ï¼Œæ·»åŠ åˆ°æŸ¥è¯¢ä¸Šä¸‹æ–‡ä¸­å¹¶å‡†å¤‡ä¼ é€’ç»™RAGå·¥å…·
    if medical_attachment_info and medical_attachment_info["status"] in ["success", "success_from_cache", "success_from_user_data", "success_from_previous_data"]:
        enhanced_query = f"""ç”¨æˆ·é—®é¢˜: {new_user_message}

âš ï¸ æ³¨æ„ï¼šç”¨æˆ·æä¾›äº†åŒ»ç–—é™„ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨å›¾åƒåˆ†æç»“æœå¢å¼ºRAGæ£€ç´¢ã€‚

ğŸš¨ å¼ºåˆ¶è¦æ±‚ï¼šå¿…é¡»è°ƒç”¨medical_qa_searchå·¥å…·ï¼Œä½¿ç”¨ä»¥ä¸‹å‚æ•°ï¼š
- question: "{new_user_message}"  
- image_analysis: å®Œæ•´çš„åŒ»ç–—å›¾åƒåˆ†æç»“æœ

è¿™æ ·RAGç³»ç»Ÿå°†åŸºäºå›¾åƒå†…å®¹è¿›è¡Œå¢å¼ºæ£€ç´¢ï¼"""
        input_data["query"] = enhanced_query
        # å°†åŒ»ç–—é™„ä»¶ä¿¡æ¯å­˜å‚¨ä»¥ä¾¿åç»­ä¼ é€’ç»™å·¥å…·
        input_data["medical_attachment_info"] = medical_attachment_info
        logger.info("å·²å°†åŒ»ç–—é™„ä»¶åˆ†æç»“æœæ•´åˆåˆ°æŸ¥è¯¢ä¸­ï¼Œå‡†å¤‡ä¼ é€’ç»™RAGå·¥å…·")
    
    # å·²ç§»é™¤tokenæ¶ˆè€—ç»Ÿè®¡
    
    logger.info(f"å¼€å§‹å¹¶è¡Œè°ƒç”¨è¯­è¨€æ£€æµ‹AIå’Œæ•°æ®æ”¶é›†AI: æŸ¥è¯¢='{new_user_message}'")
    
    # å¢å¼ºçš„å“åº”ç¼“å­˜æ£€æŸ¥
    import hashlib
    cache_content = f"{user_ip}_{new_user_message}_{user_data.language}_{medical_file or ''}"
    cache_key = hashlib.md5(cache_content.encode('utf-8')).hexdigest()
    
    # æ£€æŸ¥ä¸“ç”¨å“åº”ç¼“å­˜
    if cache_key in _response_cache:
        cache_entry = _response_cache[cache_key]
        if time.time() - cache_entry['timestamp'] < 1800:  # 30åˆ†é’Ÿç¼“å­˜
            logger.info(f"âš¡ ä½¿ç”¨å“åº”ç¼“å­˜: {new_user_message[:50]}...")
            return ChatResponse(
                user_ip=user_ip,
                ai_reply=cache_entry['response'],
            )
        else:
            del _response_cache[cache_key]
    
    # æ£€æŸ¥æ—§ç‰ˆç®€å•ç¼“å­˜ï¼ˆå…¼å®¹æ€§ï¼‰
    old_cache_key = f"{user_ip}_{new_user_message}_{user_data.language}"
    cached_response = await simple_cache.get("response", old_cache_key)
    
    if cached_response:
        logger.info(f"ä½¿ç”¨ç¼“å­˜çš„å®Œæ•´å“åº”: {new_user_message[:50]}...")
        return ChatResponse(
            user_ip=user_ip,
            ai_reply=cached_response,
        )
    
    # ç®€åŒ–çš„è¯­è¨€æ£€æµ‹
    try:
        # æ›´æ–°ç”¨æˆ·è¯­è¨€è®¾ç½®
        updated_user_data_dict = await detect_and_update_language(new_user_message, user_data.model_dump(), user_ip)
        user_data = data.model_validate(updated_user_data_dict)
        
        # æ‰§è¡Œæ•°æ®æ”¶é›†AI
        output = await asyncio.wait_for(
            chain.ainvoke(input_data),
            timeout=30.0
        )
        
    except Exception as e:
        logger.error(f"AIè°ƒç”¨å‡ºç°é”™è¯¯: {e}")
        # ä½¿ç”¨é™çº§æ–¹æ¡ˆ
        language = user_data.language or "zh"
        fallback_messages = {
            "zh": "æŠ±æ­‰ï¼Œç³»ç»Ÿæš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            "English": "Sorry, the system is temporarily busy. Please try again later.",
            "ja": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ã‚·ã‚¹ãƒ†ãƒ ãŒä¸€æ™‚çš„ã«æ··é›‘ã—ã¦ã„ã¾ã™ã€‚å¾Œã§ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
            "ko": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì¼ì‹œì ìœ¼ë¡œ ë°”ì©ë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
        }
        return ChatResponse(
            user_ip=user_ip,
            ai_reply=fallback_messages.get(language, fallback_messages["zh"]),
        )
    
    logger.info(f"å¯¹è¯AIè¾“å‡º: {output}")


    # å¤„ç†å·¥å…·è°ƒç”¨ - ä¼˜å…ˆä½¿ç”¨output.tool_callsï¼Œå¤‡ç”¨additional_kwargs
    tool_calls = getattr(output, 'tool_calls', None) or output.additional_kwargs.get("tool_calls", [])
    
    # å¦‚æœæ²¡æœ‰åŸç”Ÿå·¥å…·è°ƒç”¨ï¼Œå°è¯•è§£ææ–‡æœ¬ä¸­çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤
    if not tool_calls and tools and len(tools) > 0:
        logger.info(f"æœªæ£€æµ‹åˆ°åŸç”Ÿå·¥å…·è°ƒç”¨ï¼Œå°è¯•ä»æ–‡æœ¬è§£æã€‚å¯ç”¨å·¥å…·: {[tool.name for tool in tools]}")
        logger.info(f"AIå›å¤å†…å®¹é¢„è§ˆ: {output.content[:200]}...")
        tool_calls = extract_tool_calls_from_text(output.content, tools)
        if tool_calls:
            logger.info(f"ä»æ–‡æœ¬ä¸­è§£æåˆ°å·¥å…·è°ƒç”¨: {len(tool_calls)}ä¸ª")
        else:
            logger.warning("æœªèƒ½ä»æ–‡æœ¬ä¸­è§£æåˆ°ä»»ä½•å·¥å…·è°ƒç”¨")
    
    logger.info(f"æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(tool_calls)}ä¸ª")
    if tool_calls:
        logger.info(f"å·¥å…·è°ƒç”¨è¯¦æƒ…: {tool_calls}")
    
    final_reply = output.content
    
    if tool_calls and tools and len(tools) > 0 and mcp_server:
        try:
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logger.info(f"å·¥å…·è°ƒç”¨å‰æ£€æŸ¥: medical_attachment_infoå­˜åœ¨={medical_attachment_info is not None}")
            if medical_attachment_info:
                logger.info(f"åŒ»ç–—é™„ä»¶çŠ¶æ€: {medical_attachment_info.get('status', 'unknown')}")
                logger.info(f"extracted_contenté•¿åº¦: {len(medical_attachment_info.get('extracted_content', ''))}")
            
            # å¦‚æœæœ‰åŒ»ç–—é™„ä»¶ä¿¡æ¯ä¸”è°ƒç”¨äº†medical_qa_searchå·¥å…·ï¼Œå¢å¼ºå·¥å…·å‚æ•°
            if medical_attachment_info and medical_attachment_info["status"] in ["success", "success_from_cache"]:
                enhanced_tool_calls = []
                for tool_call in tool_calls:
                    if ("function" in tool_call and 
                        tool_call["function"]["name"] == "medical_qa_search"):
                        # è§£æç°æœ‰å‚æ•°
                        import json
                        args = json.loads(tool_call["function"]["arguments"]) if tool_call["function"]["arguments"] else {}
                        # æ·»åŠ å›¾åƒåˆ†æå‚æ•°
                        args["image_analysis"] = medical_attachment_info["extracted_content"]
                        # æ›´æ–°å·¥å…·è°ƒç”¨
                        enhanced_tool_call = tool_call.copy()
                        enhanced_tool_call["function"]["arguments"] = json.dumps(args, ensure_ascii=False)
                        enhanced_tool_calls.append(enhanced_tool_call)
                        logger.info(f"âœ… æˆåŠŸå¢å¼ºmedical_qa_searchå·¥å…·è°ƒç”¨ï¼Œæ·»åŠ å›¾åƒåˆ†æå‚æ•°ï¼ˆé•¿åº¦: {len(args['image_analysis'])}ï¼‰")
                        logger.info(f"å¢å¼ºåçš„å·¥å…·å‚æ•°: {args}")
                    else:
                        enhanced_tool_calls.append(tool_call)
                tool_calls = enhanced_tool_calls
            else:
                logger.warning(f"âš ï¸ æœªèƒ½å¢å¼ºå·¥å…·è°ƒç”¨ - medical_attachment_infoçŠ¶æ€: {medical_attachment_info.get('status', 'None') if medical_attachment_info else 'None'}")
            
            # ä½¿ç”¨æ­£ç¡®çš„æœåŠ¡å™¨åˆ›å»ºä¼šè¯ï¼Œå¹¶é‡æ–°åŠ è½½å·¥å…·
            async with mcp_server.session("medical_tools") as session:
                # é‡æ–°åŠ è½½å·¥å…·ä»¥ç¡®ä¿sessionæ˜¯æ´»è·ƒçš„
                fresh_tools = await load_mcp_tools(session)
                tool_responses = await execute_tools(tool_calls, session, fresh_tools)

            # åˆ›å»ºåŒ…å«å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯åˆ—è¡¨
            messages_for_followup = database[user_ip]["record"] + [output] + tool_responses

            # ç”Ÿæˆåç»­å¯¹è¯æç¤ºè¯ï¼ˆæ— éœ€tokenç»Ÿè®¡ï¼‰
            follow_up_prompt = get_follow_up_prompt()
            follow_up_chain = follow_up_prompt | llm_for_data

            # å†æ¬¡è°ƒç”¨æ¨¡å‹
            follow_up_output = await follow_up_chain.ainvoke({"history": messages_for_followup})
            final_reply = follow_up_output.content

            # æ›´æ–°è®°å½•
            database[user_ip]["record"].append(output)
            database[user_ip]["record"].extend(tool_responses)
            database[user_ip]["record"].append(follow_up_output)
        except Exception as e:
            logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            logger.warning("å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹AIå›å¤")
            database[user_ip]["record"].append(output)
            final_reply = output.content
    else:
        # æ²¡æœ‰å·¥å…·è°ƒç”¨æˆ–å·¥å…·ä¸å¯ç”¨ï¼Œç›´æ¥æ·»åŠ åˆ°è®°å½•
        database[user_ip]["record"].append(output)
        if tool_calls:
            logger.warning("æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ä½†å·¥å…·ä¸å¯ç”¨ï¼Œå¿½ç•¥å·¥å…·è°ƒç”¨")
        else:
            logger.info("æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")

    # ç›´æ¥ä½¿ç”¨AIçš„æ–‡æœ¬å›å¤ï¼Œä¸éœ€è¦è§£æJSONç»“æ„
    # æ›´æ–°æ•°æ®åº“ä¸­çš„æ•°æ®ï¼ˆä¿æŒç”¨æˆ·æ•°æ®ä¸å˜ï¼Œåªæ›´æ–°è¯­è¨€ï¼‰
    database[user_ip]["data"] = user_data.model_dump()

    # ç¼“å­˜å“åº”ç»“æœåˆ°ä¸“ç”¨ç¼“å­˜ï¼ˆåŒæ­¥æ‰§è¡Œï¼Œæ›´å¿«ï¼‰
    try:
        _response_cache[cache_key] = {
            'response': final_reply,
            'timestamp': time.time(),
            'original_question': new_user_message
        }
        # é™åˆ¶å“åº”ç¼“å­˜å¤§å°
        if len(_response_cache) > 500:
            oldest_key = min(_response_cache.keys(), 
                           key=lambda k: _response_cache[k]['timestamp'])
            del _response_cache[oldest_key]
        logger.info(f"ğŸ’¾ å“åº”å·²ç¼“å­˜: {new_user_message[:30]}...")
    except Exception as e:
        logger.warning(f"ç¼“å­˜å“åº”å¤±è´¥: {e}")
    
    # åŒæ—¶å¼‚æ­¥ç¼“å­˜åˆ°æ—§ç‰ˆç³»ç»Ÿï¼ˆå…¼å®¹æ€§ï¼‰
    asyncio.create_task(simple_cache.set(
        "response", 
        old_cache_key, 
        final_reply, 
        ttl=1800  # 30åˆ†é’Ÿç¼“å­˜
    ))

    # final_reply å·²ç»æ˜¯AIçš„ç›´æ¥å›å¤

    # å›å¤
    return ChatResponse(
        user_ip=user_ip,
        ai_reply=final_reply,
    )
@app.get("/cache/stats")
async def get_cache_stats():
    """è·å–æ‰€æœ‰ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è·å–ç®€åŒ–ç¼“å­˜ç»Ÿè®¡
        simple_cache_stats = simple_cache.get_stats()
        
        # è·å–åŒ»ç–—é™„ä»¶ç¼“å­˜ç»Ÿè®¡
        medical_cache_stats = medical_processor.get_cache_statistics()
        
        # è·å–æ–°å¢çš„ä¸“ç”¨ç¼“å­˜ç»Ÿè®¡
        from method import _language_cache, _response_cache
        language_cache_stats = {
            "total_entries": len(_language_cache),
            "cache_type": "language_detection"
        }
        
        response_cache_stats = {
            "total_entries": len(_response_cache),
            "cache_type": "response_cache"
        }
        
        return {
            "status": "success",
            "simple_cache": simple_cache_stats,
            "medical_attachment_cache": medical_cache_stats,
            "language_cache": language_cache_stats,
            "response_cache": response_cache_stats,
            "performance_summary": {
                "total_cache_entries": (
                    simple_cache_stats.get("memory_entries", 0) + 
                    len(_language_cache) + 
                    len(_response_cache)
                ),
                "estimated_speedup": "30-80% faster responses for cached queries"
            }
        }
    except Exception as e:
        logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return {
            "status": "error",
            "message": f"è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"
        }

@app.post("/cache/clear")
async def clear_cache():
    """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
    try:
        # æ¸…ç†ç®€åŒ–ç¼“å­˜
        cleared_count = len(simple_cache.memory_cache)
        simple_cache.memory_cache.clear()
        
        # æ¸…ç†ç£ç›˜ç¼“å­˜
        import shutil
        if simple_cache.cache_dir.exists():
            shutil.rmtree(simple_cache.cache_dir)
            simple_cache.cache_dir.mkdir(exist_ok=True)
        
        # æ¸…ç†æ–°å¢çš„ä¸“ç”¨ç¼“å­˜
        from .method import _language_cache, _response_cache
        language_cleared = len(_language_cache)
        response_cleared = len(_response_cache)
        _language_cache.clear()
        _response_cache.clear()
        
        # é‡ç½®ç»Ÿè®¡
        simple_cache.stats = {'hits': 0, 'misses': 0}
        
        total_cleared = cleared_count + language_cleared + response_cleared
        
        return {
            "status": "success",
            "message": f"å·²æ¸…ç†æ‰€æœ‰ç¼“å­˜",
            "details": {
                "simple_cache": cleared_count,
                "language_cache": language_cleared,
                "response_cache": response_cleared,
                "total_cleared": total_cleared
            }
        }
    except Exception as e:
        logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        return {
            "status": "error",
            "message": f"æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}"
        }

@app.delete("/cache/user/{user_ip}")
async def clear_user_cache(user_ip: str):
    """æ¸…ç†ç‰¹å®šç”¨æˆ·çš„åŒ»ç–—é™„ä»¶ç¼“å­˜"""
    try:
        removed_count = medical_processor.clear_user_medical_cache(user_ip)
        return {
            "status": "success",
            "message": f"å·²æ¸…ç†ç”¨æˆ· {user_ip} çš„ {removed_count} ä¸ªç¼“å­˜æ¡ç›®",
            "removed_count": removed_count
        }
    except Exception as e:
        logger.error(f"æ¸…ç†ç”¨æˆ·ç¼“å­˜å¤±è´¥: {e}")
        return {
            "status": "error", 
            "message": f"æ¸…ç†ç”¨æˆ·ç¼“å­˜å¤±è´¥: {str(e)}"
        }

@app.get("/cache/check/{user_ip}/{filename}")
async def check_attachment_cache(user_ip: str, filename: str):
    """æ£€æŸ¥ç‰¹å®šåŒ»ç–—é™„ä»¶æ˜¯å¦å·²ç¼“å­˜"""
    try:
        is_cached = medical_processor.is_attachment_cached(user_ip, filename)
        return {
            "status": "success",
            "user_ip": user_ip,
            "filename": filename,
            "is_cached": is_cached
        }
    except Exception as e:
        logger.error(f"æ£€æŸ¥ç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
        return {
            "status": "error",
            "message": f"æ£€æŸ¥ç¼“å­˜çŠ¶æ€å¤±è´¥: {str(e)}"
        }

"""
#å¼ƒç”¨çš„é¢„åˆ¶è¯
@app.post("/preset_words", response_model=PresetWordsResponse)   #postè¯·æ±‚ï¼Œæ¥æ”¶ç”¨æˆ·IPï¼Œè¿”å›é¢„åˆ¶è¯åˆ—è¡¨
async def get_preset_words(request: PresetWordsRequest):
    prompt_preset_words_and_model = prompt_prefabricated_words | llm_for_generating_preset
    # è·å–ç”¨æˆ·ipå¹¶è·å¾—ç”¨æˆ·æ•°æ®å’Œæ¶ˆæ¯
    user_ip = request.user_ip
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°ç”¨æˆ·
    check_user(user_ip, database)
    data_and_message = database[user_ip]
    
    # è·å–ç”¨æˆ·è¯­è¨€åå¥½ç”¨äºæ—¥å¿—è®°å½•
    user_language = data_and_message.get("data", {}).get("language", "English")
    logger.info(f"é¢„åˆ¶è¯ç”Ÿæˆè¯·æ±‚ - ç”¨æˆ·IP: {user_ip}, è¯­è¨€: {user_language}")
    
    # è¯·æ±‚AIç”Ÿæˆé¢„åˆ¶è¯ï¼ˆAIä¼šè‡ªåŠ¨æ ¹æ®languageå­—æ®µé€‰æ‹©è¯­è¨€ï¼‰
    preset_output = await prompt_preset_words_and_model.ainvoke({"data_and_ai_message": data_and_message})
    preset_words_output = parser_prefabricated_words.parse(preset_output.content)
    
    logger.info(f"é¢„åˆ¶è¯ç”Ÿæˆå®Œæˆ - ç”Ÿæˆæ•°é‡: {len(preset_words_output.words)}")
    
    # è¿”å›é¢„åˆ¶è¯
    return PresetWordsResponse(
        preset_words=preset_words_output.words
    )
"""

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("client:app", host="localhost", port=8004, reload=True)
